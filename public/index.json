[
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Create a gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Open the Amazon VPC console In the navigation pane, choose Endpoints, then click Create Endpoint: You will see 6 existing VPC endpoints that support AWS Systems Manager (SSM). These endpoints were deployed automatically by the CloudFormation Templates for this workshop.\nIn the Create endpoint console: Specify name of the endpoint: s3-gwe In service category, choose AWS services In Services, type s3 in the search box and choose the service with type gateway For VPC, select VPC Cloud from the drop-down. For Configure route tables, select the route table that is already associated with two subnets (note: this is not the main route table for the VPC, but a second route table created by CloudFormation). For Policy, leave the default option, Full Access, to allow full access to the service. You will deploy a VPC endpoint policy in a later lab module to demonstrate restricting access to S3 buckets based on policies. Do not add a tag to the VPC endpoint at this time. Click Create endpoint, then click x after receiving a successful creation message. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Nguyen Truong Huy.\nPhone Number: 0827338992.\nEmail: truonghuy20203@gmail.com .\nUniversity: FPT University.\nMajor: Information System.\nClass: AWS082025.\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern.\nInternship Duration: From September to December 2025.\nReport Content: Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "VPC endpoints VPC endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components. They allow communication between your compute resources and AWS services without imposing availability risks. Compute resources running in VPC can access Amazon S3 using a Gateway endpoint. PrivateLink interface endpoints can be used by compute resources running in VPC or on-premises. Workshop overview In this workshop, you will use two VPCs.\n\u0026ldquo;VPC Cloud\u0026rdquo; is for cloud resources such as a Gateway endpoint and an EC2 instance to test with. \u0026ldquo;VPC On-Prem\u0026rdquo; simulates an on-premises environment such as a factory or corporate datacenter. An EC2 instance running strongSwan VPN software has been deployed in \u0026ldquo;VPC On-prem\u0026rdquo; and automatically configured to establish a Site-to-Site VPN tunnel with AWS Transit Gateway. This VPN simulates connectivity from an on-premises location to the AWS cloud. To minimize costs, only one VPN instance is provisioned to support this workshop. When planning VPN connectivity for your production workloads, AWS recommends using multiple VPN devices for high availability. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Prepare the environment",
	"tags": [],
	"description": "",
	"content": "To prepare for this part of the workshop you will need to:\nDeploying a CloudFormation stack Modifying a VPC route table. These components work together to simulate on-premises DNS forwarding and name resolution.\nDeploy the CloudFormation stack The CloudFormation template will create additional services to support an on-premises simulation:\nOne Route 53 Private Hosted Zone that hosts Alias records for the PrivateLink S3 endpoint One Route 53 Inbound Resolver endpoint that enables \u0026ldquo;VPC Cloud\u0026rdquo; to resolve inbound DNS resolution requests to the Private Hosted Zone One Route 53 Outbound Resolver endpoint that enables \u0026ldquo;VPC On-prem\u0026rdquo; to forward DNS requests for S3 to \u0026ldquo;VPC Cloud\u0026rdquo; Click the following link to open the AWS CloudFormation console. The required template will be pre-loaded into the menu. Accept all default and click Create stack. It may take a few minutes for stack deployment to complete. You can continue with the next step without waiting for the deployemnt to finish.\nUpdate on-premise private route table This workshop uses a strongSwan VPN running on an EC2 instance to simulate connectivty between an on-premises datacenter and the AWS cloud. Most of the required components are provisioned before your start. To finalize the VPN configuration, you will modify the \u0026ldquo;VPC On-prem\u0026rdquo; routing table to direct traffic destined for the cloud to the strongSwan VPN instance.\nOpen the Amazon EC2 console\nSelect the instance named infra-vpngw-test. From the Details tab, copy the Instance ID and paste this into your text editor\nNavigate to the VPC menu by using the Search box at the top of the browser window.\nClick on Route Tables, select the RT Private On-prem route table, select the Routes tab, and click Edit Routes.\nClick Add route. Destination: your Cloud VPC cidr range Target: ID of your infra-vpngw-test instance (you saved in your editor at step 1) Click Save changes "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Connect and get acquainted with members of the First Cloud Journey (FCJ).\nUnderstand basic AWS services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get to know FCJ members. - Read and note the rules and regulations of the internship unit. 08/09/2025 09/09/2025 3 - Learn about Cloud Computing. 09/09/2025 10/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Study at the office. - Continue learning about Cloud Computing. - First random blog translation attempt. 10/09/2025 11/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Learn about basic VPC concepts: + Subnet. + Route Table. + Security. - Watch labs 1 on AWS. 11/09/2025 13/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Continue learning about Cloud Computing on YouTube. 12/09/2025 14/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 1 Achievements Monday (08/09/2025):\nConnected and got acquainted with members of the First Cloud Journey (FCJ).\nRead, took notes, and understood the rules and regulations of the internship unit.\nTuesday (09/09/2025):\nStudied and understood the basic concepts of Cloud Computing. Wednesday (10/09/2025):\nGo to the office for studying.\nAttended the internship office and got familiar with the working environment.\nContinued learning about Cloud Computing.\nFirst random AWS blog translation attempt.\nThursday (11/09/2025):\nLearned about VPC (Virtual Private Cloud) and its fundamental components:\nSubnet.\nRoute Table.\nSecurity Group.\nWatched and took notes on AWS Lab 1 about network configuration.\nFriday (12/09/2025):\nContinued learning about Cloud Computing through YouTube.\nUnderstanding of cloud infrastructure operations and AWS benefits.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Practice using AWS technologies.\nUnderstand basic AWS services.\nTasks to be carried out this week Day Task Start Date Completion Date Reference Material 2 - Continue learning AWS on YouTube. - Explore and understand AWS technologies. 15/09/2025 15/09/2025 3 - Attend a team meeting to discuss project ideas, programming languages, and technologies to be used. 16/09/2025 16/09/2025 4 - Learn AWS through YouTube videos. 17/09/2025 17/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Attend the AWS Cloud Day Vietnam event at the office. 18/09/2025 18/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Learn how to use AWS technologies. 19/09/2025 21/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 2 Achievements: Monday (15/09/2025):\nContinued learning AWS on YouTube, reinforcing basic concepts of cloud computing.\nExplored core AWS technologies and services, such as Compute, Storage, Database, and Networking.\nTuesday (16/09/2025):\nParticipated in a team meeting to discuss project ideas.\nAgreed on the programming language, technologies, and AWS services to be used during project development.\nWednesday (17/09/2025):\nContinued studying AWS content through instructional videos.\nBecame familiar with the AWS Management Console and how to access different services.\nThursday (18/09/2025):\nAttended the AWS Cloud Day Vietnam 2025 event at the office.\nListened to AWS experts discuss Cloud Computing trends, AI/ML, and Digital Transformation in businesses.\nFriday (19/09/2025):\nLearned how to use and work with AWS technologies.\nBegan getting familiar with deploying and managing basic AWS services.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Understand how to use AWS technologies.\nLearn basic AWS services, including how to use the Console and CLI.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS through YouTube. 22/09/2025 22/09/2025 3 - Try to translate the second random blog. 23/09/2025 23/09/2025 Youtube: AWS Cloud Journey 4 - Learn about Compute VM on AWS. - Study EC2 Instance Types - Including: + Amazon Elastic Compute Cloud (EC2). + Amazon Lightsail. 24/09/2025 24/09/2025 https://aws.amazon.com/ec2/instance-types/?ncl=h_is/ 5 - Study basic EC2 Concepts:\n+ Amazon EFS/FSX. + AWS Application Migration Service (MGN). 25/09/2025 27/09/2025 https://aws.amazon.com/ec2/instance-types/?ncl=h_is/ 6 - Practice: + Create an EC2 instance. + Create a database. 26/09/2025 28/09/2025 Week 3 Achievements: Monday (22/09/2025):\nLearn the basic concepts of AWS through YouTube tutorials.\nGained an overview of AWS core services.\nTuesday (23/09/2025):\nSecond random AWS blog translation attempt. Wednesday (24/09/2025):\nStudied Compute VM on AWS.\nExplored the Compute service group on AWS, including:\nAmazon EC2.\nAmazon Lightsail.\nThursday (25/09/2025):\nUnderstanding of Basic EC2 concepts.\nLearned how to choose the right instance type.\nStudied the following services:\nAmazon EFS / FSX.\n**AWS Application Migration Service (MGN).\n→ Gained comprehensive knowledge of EC2 instance types.\nFriday (26/09/2025):\nSuccessfully completed hands-on practice:\nCreated an EC2 instance.\nCreated a database on AWS.\nBecame familiar with using the AWS Management Console.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Create an AWS account.\nPractice using AWS modules and core services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create an AWS account. - Successfully activate $200 free credits. 29/10/2025 29/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 3 - Perform basic operations on AWS: + Create an EC2 Instance. + Learn about Billing \u0026amp; Cost Management.\n+ Explore Aurora \u0026amp; RDS. 30/10/2025 01/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 4 - Explore and practice with EC2. - Get familiar with Billing and Cost Management. - Install and configure AWS CLI for basic resource management. 01/10/2025 02/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 5 - Learn about AWS Private Certificate Authority. - Understand how to manage Databases on AWS. - Translate 3 assigned blog post. 02/10/2025 02/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 6 - Study AWS Lambda and Amazon Bedrock. - Practice deploying serverless services. - Review basic operations on Console \u0026amp; CLI. - Successfully push the project folder to GitHub. 03/10/2025 05/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] Week 4 Achievements Monday (29/09/2025):\nSuccessfully created an AWS Free Tier account.\nCompleted activation of the $200 free credit.\nTuesday (30/09/2025):\nLaunched and operated an EC2 Instance.\nBecame familiar with Billing \u0026amp; Cost Management.\nWednesday (01/10/2025):\nPracticed more deeply with EC2.\nUnderstood and used key features in Billing and Cost Management.\nInstalled and configured AWS CLI for managing basic resources.\nThursday (02/10/2025):\nLearned about AWS Private Certificate Authority.\nBecame familiar with database management in AWS.\nTranslate 3 assigned blog post.\nFriday (03/10/2025):\nStudied and practiced with AWS Lambda and Amazon Bedrock.\nExperimented with serverless deployment.\nPracticed essential operations on Console \u0026amp; CLI.\nSuccessfully pushed the project folder to GitHub.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Continue learning AWS on YouTube.\nUnderstand core AWS services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study at the office. - Learn Module 03: Amazon Elastic Compute Cloud (EC2): + AMI / Backup / Key Pair. + Elastic block store. + User data. + Meta data. 06/10/2025 06/10/2025 Youtube: AWS Cloud Journey 3 - Continue studying Amazon EC2: + EC2 auto scaling. + EFS/FSX. + Lightsail. + MGN. 07/10/2025 07/10/2025 Youtube: AWS Cloud Journey 4 - Study at the office. - Translate and edit AWS blog content. 08/10/2025 08/10/2025 Youtube: AWS Cloud Journey 5 - Study AWS Storage Services: + Amazon Simple Storage. Service - S3. + Amazon Storage Gateway. + Snow Family. + Disaster Recovery on AWS. + AWS Backup. - Complete and review translated blog. 09/10/2025 11/10/2025 Youtube: AWS Cloud Journey 6 - Continue Module 04: + Access Point. + Storage Class. + S3 Static Website \u0026amp; CORS. + Control Access. + Object Key \u0026amp; Performance. + Glacier. 10/10/2025 12/10/2025 Youtube: AWS Cloud Journey Week 5 Achievements Monday (06/10/2025):\nGo to the office for studying.\nLearned and practiced with Amazon EC2: created and configured EC2 instances.\nPracticed AMI, EBS, User Data, and Meta Data.\nGenerated and used Key Pairs for secure access to instances.\nTuesday (07/10/2025):\nGained knowledge about EC2 Auto Scaling.\nStudied additional AWS storage options: EFS and FSx.\nExplored Lightsail and MGN for lightweight and migration use cases.\nWednesday (08/10/2025):\nGo to the office for studying.\nTranslated and edited an AWS blog.\nThursday (09/10/2025):\nExplored AWS Storage Services in depth:\nAmazon S3: Created buckets, uploaded files, configured ACLs, Bucket Policies, CORS, and Static Website Hosting.\nAmazon Storage Gateway: Connected on-premises data with AWS cloud storage.\nAWS Snow Family: Learned about large-scale data migration solutions.\nAWS Backup: Studied centralized data backup and recovery processes.\nDisaster Recovery (DR) on AWS: Understood strategies for resilience.\nCompleted and reviewed translated blog.\nFriday (10/10/2025):\nContinued studying Module 04: learned about Access Point and Storage Class in S3.\nPracticed Static Website Hosting and CORS configuration on S3.\nStudied Object Key, storage performance, and Amazon Glacier for long-term data archiving.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Continue watching AWS service tutorials on YouTube.\nPrepare knowledge for the midterm exam.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Watch Module 5 – Shared Responsibility Model. - Study Amazon Identity and Access Management (IAM). 13/10/2025 13/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Continue Module 5: + Watch Amazon Identity and access management. + Watch Amazon Cognito. + AWS Organization. 14/10/2025 14/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Watch AWS Identity Center. - Watch Amazon Key Management Service. - Watch AWS Security Hub. 15/10/2025 15/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Study at the office. - Watch Module 6 - Database Concept + Amazon RDS \u0026amp; Amazon Aurora + Redshift \u0026amp; Elasticache - Double-check translated blog articles. 16/10/2025 18/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Continue reviewing Module 6 labs. - Revise Modules 1–6 to prepare for the midterm exam. 18/10/2025 19/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 6 Achievements Monday (13/10/2025):\nWatched Module 5 – Shared Responsibility Model.\nStudied Amazon Identity and Access Management (IAM) to understand user and role permissions.\nTuesday (14/10/2025):\nContinued learning about IAM.\nStudied Amazon Cognito for authentication and user identity management.\nLearned AWS Organizations to manage multiple AWS accounts efficiently.\nWednesday (15/10/2025):\nStudied AWS Identity Center for centralized access management.\nExplored Amazon Key Management Service (KMS) for key creation, encryption, and security management.\nLearned about AWS Security Hub, a tool for continuous security monitoring.\nThursday (16/10/2025):\nStudied at the office and practiced using AWS services.\nWatch Module 6.\nCarefully checked translated AWS blogs for accuracy.\nFriday (17/10/2025):\nContinued with Module 6 labs for hands-on learning.\nReviewed Modules 1–6 thoroughly to prepare for the upcoming midterm exam.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Review AWS lab modules.\nStudy materials for the midterm exam.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review Lab Module 1. - Review midterm exam topics. 20/10/2025 21/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Review Modules 1 and Lab 1. 21/10/2025 21/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Review Modules 2 and Lab 2. 22/10/2025 22/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Review Modules 3 \u0026amp; 4 and their labs. Go to the office for studying 23/10/2025 25/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Review Modules 5 \u0026amp; 6 and their labs. Go to the office for studying 24/10/2025 26/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 7 Achievements Monday (20/10/2025):\nReviewed Lab Module 1 to reinforce practical AWS concepts.\nReview midterm exam content.\nTuesday (21/10/2025):\nCompleted review of Module 1 and Lab 1.\nUnderstanding of AWS basics, including global infrastructure and shared responsibility.\nWednesday (22/10/2025):\nReviewed Module 2 and Lab 2.\nPracticed hands-on exercises related to VPC, subnets, and EC2 instances.\nThursday (23/10/2025):\nGo to the office for studying.\nReviewed Modules 3 \u0026amp; 4 and its labs.\nStrengthened understanding of S3, EBS, and Disaster Recovery concepts.\nFriday (24/10/2025):\nGo to the office for studying.\nReviewed Module 5 \u0026amp; 6 and its labs.\nConsolidated knowledge across Modules 1–6 in preparation for the midterm exam.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Midterm Exam Review this week. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review theory for Module 1-2. 27/10/2025 27/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Review theory for Module 3-4. 28/10/2025 29/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Review theory for Module 5-6. 29/10/2025 29/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Review all theory from 6 modules. 30/10/2025 30/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Go to the office for the Midterm Exam. 31/10/2025 31/10/2025 Week 8 Achievements: Monday (27/10/2025):\nReview Module 1–2. Tuesday (28/10/2025):\nReview Module 3–4. Wednesday (29/10/2025):\nReview Module 5–6. Thursday (30/10/2025):\nSummarize and consolidate all knowledge from Module 1–6. Friday (31/10/2025):\nMidterm Exam at the Office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Review the structure of the project. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read the project documentation. 03/11/2025 03/11/2025 3 - Review the project diagram. 04/11/2025 04/11/2025 4 - Identify the services required by the project. 05/11/2025 05/11/2025 5 - Determine how many services need to be applied. 06/11/2025 06/11/2025 6 - Review the overall structure of the project. 07/11/2025 07/11/2025 Week 9 Achievements: Monday (03/11/2025):\nRead through the project documentation to understand its purpose and scope. Tuesday (04/11/2025):\nReviewed the project diagram to visualize the system architecture. Wednesday (05/11/2025):\nExamined which services are required for the project implementation. Thursday (06/11/2025):\nDetermined the total number of services needed and how they integrate with the system. Friday (07/11/2025):\nReviewed the overall structure of the project to consolidate understanding. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Typically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting familiar with AWS and its basic services.\nWeek 2: Practicing with technologies and understanding basic AWS services.\nWeek 3: Understanding how to use AWS technologies and basic services, including both the Console and CLI.\nWeek 4: Creating an AWS account and working with AWS modules.\nWeek 5: Continuing AWS learning through YouTube resources.\nWeek 6: Exploring more AWS services via YouTube.\nWeek 7: Reviewing modules and preparing for the Midterm\nWeek 8: Comprehensive review and taking the Midterm exam\nWeek 9: Exploring the project structure and related services\nWeek 10: Reviewing and analyzing the project’s workflow\nWeek 11: Implement coding project \u0026amp; participate in AWS events\nWeek 12: Coding, testing modules \u0026amp; participating in AWS events\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-s3-onprem/5.4.2-create-interface-endpoint/",
	"title": "Create an S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "In this section you will create and test an S3 interface endpoint using the simulated on-premises environment deployed as part of this workshop.\nReturn to the Amazon VPC menu. In the navigation pane, choose Endpoints, then click Create Endpoint.\nIn Create endpoint console:\nName the interface endpoint In Service category, choose aws services In the Search box, type S3 and press Enter. Select the endpoint named com.amazonaws.us-east-1.s3. Ensure that the Type column indicates Interface. For VPC, select VPC Cloud from the drop-down. Make sure to choose \u0026ldquo;VPC Cloud\u0026rdquo; and not \u0026ldquo;VPC On-prem\u0026rdquo;\nExpand Additional settings and ensure that Enable DNS name is not selected (we will use this in the next part of the workshop) Select 2 subnets in the following AZs: us-east-1a and us-east-1b For Security group, choose SGforS3Endpoint: Keep the default policy - full access and click Create endpoint Congratulation on successfully creating S3 interface endpoint. In the next step, we will test the interface endpoint.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "IAM permissions Add the following IAM permission policy to your user account to deploy and cleanup this workshop.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Provision resources using CloudFormation In this lab, we will use N.Virginia region (us-east-1).\nTo prepare the workshop environment, deploy this CloudFormation Template (click link): PrivateLinkWorkshop . Accept all of the defaults when deploying the template.\nTick 2 acknowledgement boxes Choose Create stack The ClouddFormation deployment requires about 15 minutes to complete.\n2 VPCs have been created 3 EC2s have been created "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "AWS Cloud Health Dashboard Comprehensive AWS Infrastructure Monitoring and Optimization Solution 1. Executive Summary. AWS Cloud Health Dashboard is a monitoring and optimization platform designed to help businesses and individuals effectively manage the costs, security, and performance of their AWS infrastructure.\nThe platform leverages a lightweight architecture built on EC2 and DynamoDB, integrating key AWS services such as CloudWatch, Cost Explorer, and Security Hub to deliver real-time monitoring, data visualization, and cost analytics.\nKey Highlights:\nOperational Cost: $12–18/month (leveraging AWS Free Tier). CloudWatch Integration: Real-time metrics tracking and alerting. Cost Analysis: Insights and optimization recommendations via AWS APIs. Real-Time Dashboard: Efficient data caching for fast performance. Scalable \u0026amp; Maintainable: Simple architecture for easy maintaining and scaling. 2. Problem Statement. Current Challenges:\nMany organizations and individual AWS users face several common issues:\nUncontrolled Costs:\nLack of centralized monitoring tools often leads to unexpected AWS billing spikes.\nLimited Security Visibility:\nNo unified dashboard to aggregate and visualize security findings.\nScattered Metrics:\nUsers must navigate across multiple AWS consoles to view performance and cost data.\nLack of Historical Data:\nCloudWatch retains metrics for only 15 days under the Free Tier.\nNo Custom Alerting:\nComplex or multi-condition alert configurations are difficult to implement.\nProposed Solution:\nCloud Health Dashboard delivers a centralized monitoring and optimization platform with the following key features:\nCentralized Monitoring:\nA single dashboard integrating CloudWatch, Cost Explorer, and Security Hub data.\nData Persistence with DynamoDB:\nFour dedicated tables: CloudHealthMetrics, CloudHealthCosts, SecurityFindings, and Recommendations. Automatic TTL policies for efficient data lifecycle management: Metrics: 30 days. Costs: 365 days. Security: 90 days. Recommendations: 180 days. On-Demand pricing to minimize cost. Optimized query patterns using GSIs for efficient access across data types. Cost analysis:\nHistorical cost trends. Service breakdown. AWS Cost Explorer recommendations integration. Budget alerts. Security monitoring:\nSecurity Hub findings aggregation. GuardDuty threat detection display. Compliance status tracking. Severity-based filtering. Intelligent recommendations:\nCost optimization suggestions. Performance improvements. Security enhancements. Impact-based prioritization. Performance Enhancements:\nRedis Caching to minimize AWS API calls and improve response time. Pre-Collected Data stored in DynamoDB for quick retrieval. WebSocket Integration for real-time data updates on the dashboard. Benefits and ROI. Cost Savings:\nFull visibility into underutilized or idle resources. Leverages AWS native cost recommendations (Cost Explorer, Trusted Advisor). Platform operating cost: only $12–18/month. Potential cost reduction: 15–25% by identifying and eliminating waste. Enhanced Visibility:\nUnified single dashboard replacing 5+ separate AWS consoles. Historical data retention beyond CloudWatch limits. Custom alerts and real-time notifications for faster response. Comprehensive view of performance, cost, and security metrics. Improved Productivity:\nReduces daily monitoring time from 30 minutes to just 5 minutes. Automated data collection and report generation. Proactive alerts prevent downtime and overspending. Actionable recommendations streamline operations and decision-making. 3. Solution Architecture. Architecture Overview:\nThe platform leverages a Single EC2 Instance + DynamoDB architecture to optimize cost and simplify deployment.\nAll application components (backend, API, and dashboard) run on a single EC2 instance, while DynamoDB is used for persistent and scalable data storage.\nRaw Design Draft:\nAWS Services Used:\nAmazon EC2 (Compute):\nt3.micro instance (750h/month Free Tier). Single public subnet (no NAT Gateway needed). Components: Nginx, FastAPI, Redis, React, CloudWatch Agent. Security: Restrictive security groups, Systems Manager Session Manager. Amazon DynamoDB (Storage):\n4 specialized tables: Metrics, Costs, Security, Recommendations. On-demand pricing mode. TTL enabled for automatic cleanup. Global Secondary Indexes for query optimization. Point-in-time recovery for backups. Amazon CloudWatch:\nMetrics collection with EC2, RDS, S3, Lambda, etc. Custom metrics for application monitoring. Logs aggregation. Alarms và notifications. AWS Cost Explorer:\nCost and usage data via API. Rightsizing recommendations (AWS native). Cost forecast (AWS native). Service breakdown. AWS Security Hub:\nSecurity findings aggregation. Compliance checking. Integration with GuardDuty. Amazon GuardDuty (Optional):\nThreat detection. Anomaly monitoring. Amazon S3 (Backup):\nDynamoDB backup exports. CloudWatch logs archive. Single Public Subnet Design:\nThe EC2 instance is deployed in a public subnet with the following security measures:\nSecurity Group Configuration:\nInbound: Port 80 and 443 open to 0.0.0.0/0. Inbound: Port 22 allowed only from trusted IPs (or fully disabled). Outbound: Unrestricted (to allow AWS API calls). Access Management:\nAWS Systems Manager Session Manager used instead of SSH. IAM Roles designed with the least privilege principle. No hardcoded credentials in the source code. Monitoring \u0026amp; Logging:\nVPC Flow Logs enabled for traffic visibility. CloudWatch Alarms configured for security events. GuardDuty enabled for continuous threat detection. Architecture Decision:\nA private subnet architecture was considered but not implemented due to:\nIncreased cost: Additional $33/month for NAT Gateway or ~$14/month for VPC Endpoints. Not suitable for a learning/portfolio project scope. Public subnet with proper security best practices is sufficient for this use case. Demonstrates cost-aware decision making. This architecture is appropriate for development or demo environments.\nFor production deployments, private subnets with NAT Gateways or VPC Endpoints should be used to enhance network isolation and security.\nComponents trong EC2 Instance:\nNginx (Port 80/443)\nReverse proxy và web server. Serve React static files. Proxy API requests to FastAPI. SSL/TLS termination. Gzip compression. FastAPI (Port 8000)\nRESTful API backend. AWS SDK integration (boto3). Business logic processing. Authentication/Authorization. Background task scheduling. Redis (Port 6379)\nCache AWS API responses. Cache DynamoDB query results. Session storage. Rate limiting. Typical cache hit rate: 60-80%. React Frontend\nSingle Page Application (SPA). Dashboard visualization. API client. Real-time updates via polling/WebSocket. Responsive design. CloudWatch Agent\nEC2 metrics collection. Application logs shipping. Custom metrics publishing. DynamoDB Table Design (4 Tables):\nTo optimize performance, data scalability, and separation of concerns, the system uses 4 specialized DynamoDB tables:\nTable 1: CloudHealthMetrics.\n{ \u0026#34;TableName\u0026#34;: \u0026#34;CloudHealthMetrics\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # service#metric_name {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # ISO timestamp ], \u0026#34;AttributeDefinitions\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;} ], \u0026#34;GlobalSecondaryIndexes\u0026#34;: [ { \u0026#34;IndexName\u0026#34;: \u0026#34;MetricNameIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # metric_name {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # timestamp ], \u0026#34;Projection\u0026#34;: {\u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34;} } ], \u0026#34;TimeToLiveSpecification\u0026#34;: { \u0026#34;AttributeName\u0026#34;: \u0026#34;ttl\u0026#34;, \u0026#34;Enabled\u0026#34;: true # Auto-delete after 30 days }, \u0026#34;BillingMode\u0026#34;: \u0026#34;PAY_PER_REQUEST\u0026#34; } # Example item: { \u0026#34;pk\u0026#34;: \u0026#34;EC2#CPUUtilization\u0026#34;, \u0026#34;sk\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;gsi1_pk\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, # For cross-service queries \u0026#34;value\u0026#34;: 75.5, \u0026#34;unit\u0026#34;: \u0026#34;Percent\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;EC2\u0026#34;, \u0026#34;metric_name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: {\u0026#34;InstanceId\u0026#34;: \u0026#34;i-1234567890abcdef0\u0026#34;}, \u0026#34;ttl\u0026#34;: 1669824000 # Unix timestamp } Table 2: CloudHealthCosts.\n{ \u0026#34;TableName\u0026#34;: \u0026#34;CloudHealthCosts\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # service {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # date#granularity ], \u0026#34;AttributeDefinitions\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;} ], \u0026#34;TimeToLiveSpecification\u0026#34;: { \u0026#34;AttributeName\u0026#34;: \u0026#34;ttl\u0026#34;, \u0026#34;Enabled\u0026#34;: true # Auto-delete after 365 days }, \u0026#34;BillingMode\u0026#34;: \u0026#34;PAY_PER_REQUEST\u0026#34; } # Example item: { \u0026#34;pk\u0026#34;: \u0026#34;EC2\u0026#34;, \u0026#34;sk\u0026#34;: \u0026#34;2025-09-22#DAILY\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2025-09-22\u0026#34;, \u0026#34;granularity\u0026#34;: \u0026#34;DAILY\u0026#34;, \u0026#34;cost\u0026#34;: 12.45, \u0026#34;usage_quantity\u0026#34;: 24.0, \u0026#34;usage_unit\u0026#34;: \u0026#34;Hrs\u0026#34;, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;tags\u0026#34;: {\u0026#34;Environment\u0026#34;: \u0026#34;Production\u0026#34;}, \u0026#34;ttl\u0026#34;: 1704067200 # Unix timestamp (1 year) } Table 3: SecurityFindings.\n{ \u0026#34;TableName\u0026#34;: \u0026#34;SecurityFindings\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # finding_type {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # finding_id ], \u0026#34;AttributeDefinitions\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;} ], \u0026#34;GlobalSecondaryIndexes\u0026#34;: [ { \u0026#34;IndexName\u0026#34;: \u0026#34;SeverityIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # severity {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # created_at ], \u0026#34;Projection\u0026#34;: {\u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34;} } ], \u0026#34;TimeToLiveSpecification\u0026#34;: { \u0026#34;AttributeName\u0026#34;: \u0026#34;ttl\u0026#34;, \u0026#34;Enabled\u0026#34;: true # Auto-delete after 90 days }, \u0026#34;BillingMode\u0026#34;: \u0026#34;PAY_PER_REQUEST\u0026#34; } # Example item: { \u0026#34;pk\u0026#34;: \u0026#34;GuardDuty\u0026#34;, \u0026#34;sk\u0026#34;: \u0026#34;finding-abc123def456\u0026#34;, \u0026#34;gsi1_pk\u0026#34;: \u0026#34;HIGH\u0026#34;, # For severity-based queries \u0026#34;gsi1_sk\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;finding_id\u0026#34;: \u0026#34;finding-abc123def456\u0026#34;, \u0026#34;finding_type\u0026#34;: \u0026#34;GuardDuty\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;HIGH\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;ACTIVE\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Suspicious network traffic detected\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Unusual outbound traffic from EC2 instance to known malicious IP\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;EC2\u0026#34;, \u0026#34;resource_id\u0026#34;: \u0026#34;i-1234567890abcdef0\u0026#34;, \u0026#34;resource_type\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;recommendation\u0026#34;: \u0026#34;Review security group rules and investigate instance activity\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;ttl\u0026#34;: 1677484800 # Unix timestamp (90 days) } Table 4: Recommendations.\n{ \u0026#34;TableName\u0026#34;: \u0026#34;Recommendations\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # type {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # created_at#rec_id ], \u0026#34;AttributeDefinitions\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34;}, {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_sk\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;N\u0026#34;} ], \u0026#34;GlobalSecondaryIndexes\u0026#34;: [ { \u0026#34;IndexName\u0026#34;: \u0026#34;ImpactIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_pk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34;}, # impact#service {\u0026#34;AttributeName\u0026#34;: \u0026#34;gsi1_sk\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34;} # estimated_savings ], \u0026#34;Projection\u0026#34;: {\u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34;} } ], \u0026#34;TimeToLiveSpecification\u0026#34;: { \u0026#34;AttributeName\u0026#34;: \u0026#34;ttl\u0026#34;, \u0026#34;Enabled\u0026#34;: true # Auto-delete after 180 days }, \u0026#34;BillingMode\u0026#34;: \u0026#34;PAY_PER_REQUEST\u0026#34; } # Example item: { \u0026#34;pk\u0026#34;: \u0026#34;cost\u0026#34;, \u0026#34;sk\u0026#34;: \u0026#34;2025-09-22T14:30:00Z#rec-789xyz\u0026#34;, \u0026#34;gsi1_pk\u0026#34;: \u0026#34;HIGH#EC2\u0026#34;, # For impact-based queries \u0026#34;gsi1_sk\u0026#34;: 50.00, # estimated_savings for sorting \u0026#34;rec_id\u0026#34;: \u0026#34;rec-789xyz\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cost\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Rightsize EC2 instance i-1234567890abcdef0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Instance runs at \u0026lt;10% CPU utilization. Consider downsizing from t3.large to t3.small\u0026#34;, \u0026#34;impact\u0026#34;: \u0026#34;HIGH\u0026#34;, \u0026#34;effort\u0026#34;: \u0026#34;LOW\u0026#34;, \u0026#34;confidence\u0026#34;: 0.92, \u0026#34;estimated_savings\u0026#34;: 50.00, \u0026#34;estimated_savings_period\u0026#34;: \u0026#34;monthly\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;EC2\u0026#34;, \u0026#34;resource_id\u0026#34;: \u0026#34;i-1234567890abcdef0\u0026#34;, \u0026#34;resource_type\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;current_config\u0026#34;: \u0026#34;t3.large\u0026#34;, \u0026#34;recommended_config\u0026#34;: \u0026#34;t3.small\u0026#34;, \u0026#34;action_steps\u0026#34;: [ \u0026#34;1. Create AMI backup\u0026#34;, \u0026#34;2. Stop instance\u0026#34;, \u0026#34;3. Change instance type\u0026#34;, \u0026#34;4. Restart and monitor\u0026#34; ], \u0026#34;implemented\u0026#34;: false, \u0026#34;created_at\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2025-09-22T14:30:00Z\u0026#34;, \u0026#34;ttl\u0026#34;: 1685894400 # Unix timestamp (180 days) } Design Rationale. The decision to use 4 specialized tables instead of 2 aggregated tables is based on clear architectural and operational benefits:\n1. Query Performance Each table is optimized for a specific access pattern:\nMetrics → Time-series queries with high write throughput. Costs → Aggregation queries by service and date range. Security → Real-time filtering by severity level. Recommendations → Impact-based sorting and status tracking. This design minimizes query latency and avoids unnecessary data scans.\n2. Separation of Concerns Clear data ownership and lifecycle management. Different TTL (Time to Live) policies for each data type. Easier to maintain, debug, and evolve over time. 3. Scalability Each table scales independently as workloads grow. Avoids hot partitions caused by data spikes in one category. GSIs (Global Secondary Indexes) tailored to specific query needs. 4. Cost Management Enables granular cost tracking per data category. Flexible TTLs reduce storage cost for short-lived data. Uses on-demand billing, ideal for variable workloads. Trade-offs Slightly higher cost (~$2–3/month) compared to 2-table setup. Slightly more complexity in deployment and maintenance. However, gains include better performance, cleaner architecture, and simpler scalability. 4. Technical Implementation. Technology Stack.\nBackend.\nPython 3.9+ with FastAPI. boto3 for AWS SDK. Redis for caching. uvicorn ASGI server. asyncio for asynchronous operations. Frontend.\nReact 18 with Vite. TanStack Query (React Query) for data fetching. Recharts for data visualization. Tailwind CSS for styling. Axios as HTTP client. Database.\nDynamoDB as the primary database (4 specialized tables). Redis as in-memory cache. DevOps.\nNginx as reverse proxy. systemd for service management. CloudWatch Agent for monitoring. Bash scripts for automation. Core Features Implementation.\nMetrics Collection Service.\nBackground job runs every 5 minutes. Collects metrics from CloudWatch API. Persists data to the CloudHealthMetrics table. Caches recent metrics in Redis (TTL = 5 minutes). Cost Analysis Service.\nDaily job collects cost data from Cost Explorer API. Stores historical cost records in CloudHealthCosts table. Generates charts and trend data for the dashboard. Surfaces AWS native recommendations (Cost Explorer, Trusted Advisor). Security Monitoring.\nPolls Security Hub and GuardDuty findings. Persists findings into the SecurityFindings table. Displays active findings with severity filtering. Triggers alerts for high/critical severity items. Read-only integration to avoid altering customer security state. Recommendations Engine.\nAnalyzes metrics, cost, and security datasets. Generates actionable recommendations. Stores suggestions in the Recommendations table. Prioritizes recommendations by impact and confidence. Tracks implementation status. API Endpoints.\nGET /api/v1/metrics - Retrieve metrics from DynamoDB. GET /api/v1/costs - Cost data and trends. GET /api/v1/security - Security findings. GET /api/v1/recommendations - Optimization recommendations. GET /api/v1/health - Health check. WS /ws - WebSocket cho real-time updates (optional). Caching Strategy.\nRedis cache for frequent queries. 5-minute TTL for metrics data. 1-hour TTL for cost data. 30-minute TTL for security findings. 2-hour TTL for recommendations. Cache invalidation on data refresh. Security Measures\nHTTPS only with Let\u0026rsquo;s Encrypt. IAM roles with least privilege. Security groups restrictive rules. No hardcoded credentials. VPC Flow Logs enabled. 5. Roadmap \u0026amp; Implementation Milestones. MVP Features (3 months, 4-member team):\nMONTH 1: Core Infrastructure \u0026amp; Basic Features.\r├─ WEEK 1: Infrastructure Setup (1 DevOps + 3 support).\r│ ├─ EC2 instance launch and configuration.\r│ ├─ DynamoDB tables creation (4 tables with GSIs).\r│ ├─ Security groups, IAM roles.\r│ ├─ Development environment setup.\r│ └─ Deliverable: Working infrastructure with 4 DynamoDB tables.\r│\r├─ WEEK 2: Backend Foundation (2 Backend + 2 Frontend start).\r│ ├─ FastAPI skeleton with basic endpoints.\r│ ├─ DynamoDB connection and basic CRUD for 4 tables.\r│ ├─ CloudWatch integration (read metrics).\r│ ├─ React app initialization.\r│ └─ Deliverable: API responding, Frontend routing.\r│\r├─ WEEK 3: Core Monitoring (2 Backend + 2 Frontend).\r│ ├─ Metrics collection background job.\r│ ├─ Store metrics in CloudHealthMetrics table.\r│ ├─ Basic dashboard page với charts.\r│ ├─ Display real CloudWatch data.\r│ └─ Deliverable: Metrics monitoring working.\r│\r└─ WEEK 4: Cost Integration (2 Backend + 2 Frontend).\r├─ Cost Explorer API integration.\r├─ Cost data storage in CloudHealthCosts table.\r├─ Cost dashboard page.\r├─ Charts and trends visualization.\r└─ Deliverable: Month 1 MVP - Metrics + Costs monitoring.\rMONTH 2: Additional Features \u0026amp; Polish.\r├─ WEEK 5: Redis Caching (1 Backend + 1 DevOps + 2 Frontend).\r│ ├─ Redis setup and integration.\r│ ├─ Cache layer implementation for 4 tables.\r│ ├─ Performance optimization.\r│ ├─ Frontend improvements.\r│ └─ Deliverable: Improved performance.\r│\r├─ WEEK 6: Security Monitoring (2 Backend + 2 Frontend).\r│ ├─ Security Hub and GuardDuty integration.\r│ ├─ Store findings in SecurityFindings table.\r│ ├─ Security dashboard page and severity filtering.\r│ ├─ Alert system basic.\r│ └─ Deliverable: Security visibility.\r│\r├─ WEEK 7: Recommendations Engine (2 Backend + 2 Frontend).\r│ ├─ AWS Cost Explorer recommendations integration.\r│ ├─ Rule-based cost optimization logic.\r│ ├─ Store in Recommendations table.\r│ ├─ Recommendations UI with impact sorting.\r│ ├─ Testing and bug fixes.\r│ └─ Deliverable: Optimization suggestions.\r│\r└─ WEEK 8: Integration \u0026amp; Testing (All 4).\r├─ End-to-end testing across 4 tables.\r├─ Bug fixes.\r├─ Performance tuning.\r├─ Documentation.\r└─ Deliverable: Stable application.\rMONTH 3: Production Ready \u0026amp; Deployment.\r├─ WEEK 9: Deployment Automation (1 DevOps + 3 support).\r│ ├─ SSL certificates setup.\r│ ├─ Nginx configuration.\r│ ├─ Systemd services.\r│ ├─ Monitoring setup.\r│ └─ Deliverable: Production deployment.\r│\r├─ WEEK 10: Documentation \u0026amp; Polish (All 4).\r│ ├─ User documentation.\r│ ├─ API documentation.\r│ ├─ DynamoDB schema documentation.\r│ ├─ Deployment guide.\r│ ├─ UI/UX improvements.\r│ └─ Deliverable: Production-ready system.\r│\r├─ WEEK 11: Testing \u0026amp; Bug Fixes (All 4).\r│ ├─ Load testing.\r│ ├─ Security testing.\r│ ├─ DynamoDB performance testing.\r│ ├─ Bug fixing.\r│ ├─ Performance optimization.\r│ └─ Deliverable: Stable production.\r│\r└─ WEEK 12: Demo Preparation (All 4).\r├─ Demo environment setup.\r├─ Presentation materials.\r├─ Final testing.\r├─ Knowledge transfer.\r└─ Deliverable: Project handover.\rPost-deployment: Maintenance \u0026amp; Enhancements.\r└─ Monitoring, bug fixes, feature requests. Phase 2 (Future Enhancements - 3-6 months after):\nMachine Learning cost prediction models. Multi-account support. Advanced analytics. Well-Architected Framework assessment. GuardDuty deep integration. AWS Config compliance tracking. Custom alerting workflows. Mobile responsive improvements. Advanced recommendation algorithms. 6. Budget Estimation. AWS Infrastructure Cost (Monthly):\nService Description Month 1 Month 2 Month 3 EC2 t3.micro 750h Free Tier $0 $0 $0 DynamoDB On-demand, 4 tables $3-4 $4-6 $6-8 CloudWatch Metrics + Logs (Free Tier) $0-1 $1-2 $2-3 Data Transfer 15GB Free Tier $0 $0-1 $1 S3 Backup storage (~5GB) $0 $0-1 $1 Security Services GuardDuty (optional) $0 $1 $1-2 TOTAL $3-5 $6-11 $11-18 Average 12-Month Cost: $12–18/month.\nDynamoDB Cost Breakdown (4 Tables):\nStorage: ~5GB total = $1.25/month.\nCloudHealthMetrics: 2GB ($0.50). CloudHealthCosts: 1GB ($0.25). SecurityFindings: 1GB ($0.25). Recommendations: 1GB ($0.25). Writes: ~800K requests/month = $1.00/month.\nMetrics: 500K writes ($0.625). Costs: 100K writes ($0.125). Security: 100K writes ($0.125). Recommendations: 100K writes ($0.125). Reads: ~4M requests/month = $2.00/month.\nEvenly distributed across 4 tables. GSI: Included in on-demand pricing.\nBackup: Free (Point-in-time recovery).\nTotal DynamoDB Cost: $4–7/month.\nNote: Costs may increase if:\nHigher metric collection frequency. More AWS services being monitored. Longer data retention periods. GuardDuty enabled (+$4–6/month). Increased security findings and recommendations. Cost Optimization Strategies:\nFully utilize AWS Free Tier (first 12 months). Use on-demand mode instead of provisioned capacity. Apply TTL for automatic data expiration per table. Use Redis caching to reduce DynamoDB reads. Set CloudWatch log retention to 7 days. Disable monitoring for unused AWS services. Perform batch writes where possible. Design efficient query patterns with GSIs. 7. Risk Assessment. Risk Matrix:\nRisk Impact Level Probability Overall Risk Budget overrun Medium Medium Medium EC2 downtime High Low Medium Scope creep Medium High High Technical complexity Medium Medium Medium AWS API rate limits Low Medium Low DynamoDB hot partitions Low Low Low Team coordination issues Medium Medium Medium Mitigation Strategies:\nCost Management\nAWS Budget alerts set at $15 and $20 thresholds. Daily cost monitoring in AWS Cost Explorer. DynamoDB on-demand mode (avoids unexpected bills). Monitor DynamoDB cost per table. Weekly cost review meetings. Kill switch to disable data collection if budget exceeds limits. EC2 Availability\nCloudWatch alarms for health checks. Systemd configured for automatic service restarts. Health check endpoint for uptime validation. Backup and recovery procedures documented. Target uptime: 98–99% (realistic for single-instance deployment). Scope Creep\nStrict MVP definition. Feature freeze after Week 8. Maintain a “Nice-to-Have” list for Phase 2. Weekly standups to track progress. Prioritize must-have features. Document 4-table design clearly for alignment. Technical Complexity\nBegin with the simplest viable solutions. Use AWS documentation extensively. Establish a code review process. Conduct technical spikes for unknown areas. Run DynamoDB data modeling workshops. Consult mentors when encountering blockers. API Rate Limits\nImplement exponential backoff on API retries. Aggressive Redis caching to reduce API calls. Monitor API usage metrics. Stay within AWS Free Tier limits. Use batch operations where possible. DynamoDB Hot Partitions\nProper partition key design. Write sharding for high-traffic tables. Monitor CloudWatch metrics for throttling. Efficient use of Global Secondary Indexes (GSI). Team Coordination\nDaily 15-minute standup meetings. Clear task ownership and accountability. Git workflow with feature branches and pull requests. Continuous documentation from Day 1. Shared knowledge base for all members. Maintain up-to-date DynamoDB schema documentation. Contingency Plan Service Failure\nSystemd auto-restart configuration. Manual recovery steps documented. Data Loss\nDaily backups to Amazon S3. DynamoDB Point-in-Time Recovery (PITR) enabled. Cost Spike\nImmediate budget alert notification. Manual review and throttle data collection. Schedule Delays\nDe-scope Phase 2 features. Focus resources solely on MVP delivery. DynamoDB Performance Issues\nFallback to direct AWS API calls. Reduce write frequency temporarily. 8. Expected Outcomes. Technical Deliverables:\nWorking Dashboard:\n4 main pages: Metrics, Costs, Security, Recommendations. Real data from AWS services. Responsive design. Basic authentication. Data Collection System:\nBackground jobs collecting metrics per 5 minutes. Cost data updated daily. Security findings updated hourly. Recommendations generated daily. Data stored in 4 specialized DynamoDB tables. Performance:\nCached response time: \u0026lt; 300ms (60-80% requests). Uncached response time: \u0026lt; 2 seconds. DynamoDB query time: 10-25ms (typical). GSI query time: 15-30ms. Target uptime: 98-99% (single instance). Cost Analysis:\nHistorical cost trends. Service breakdown charts. AWS Cost Explorer recommendations display. Budget alerts. Cost forecasting. Security Visibility:\nSecurity Hub findings dashboard. GuardDuty threat detection. Severity-based filtering using GSI. Real-time alerts cho critical findings. Compliance status overview. Recommendations System:\nCost optimization suggestions. Performance improvement recommendations. Security enhancement suggestions. Impact-based prioritization using GSI. Implementation tracking. Learning Outcomes:\nAWS Services:\nHands-on experience with EC2, DynamoDB (advanced), CloudWatch. Cost Explorer API integration. Security Hub and GuardDuty understanding. IAM roles and policies. VPC networking basics. DynamoDB data modeling best practices. Full-Stack Development:\nFastAPI backend development. React frontend development. RESTful API design. NoSQL database design patterns. DynamoDB access patterns và GSI optimization. Caching strategies. DevOps:\nLinux server administration. Nginx configuration. Service management với system. SSL/TLS setup. Monitoring và logging. Database backup strategies. Best Practices:\nSecurity-first design. Cost optimization. Code organization. Documentation. Testing strategies. NoSQL data modeling. Portfolio Value:\nProject này demonstrate:\nReal AWS production experience. Advanced DynamoDB data modeling (4 tables, GSI). Full-stack development skills. Cost-aware architecture decisions. Security consciousness. Realistic project scoping. Team collaboration. Professional documentation. Limitations \u0026amp; Trade-offs:\nDocumented limitations:\nSingle instance (no high availability). Public subnet (no private network isolation). Rule-based recommendations (no ML-powered initially). Manual AWS service additions. Limited to AWS (no multi-cloud). Documented trade-offs:\nUsing 4 tables increases complexity and cost ($2–3/month) but improves performance and maintainability. Hosting the EC2 instance in a public subnet reduces security but saves approximately $33/month. Operating with a single instance lowers availability but aligns with the project\u0026rsquo;s budget constraints. These limitations and trade-offs are conscious decisions made for cost efficiency and timeline feasibility, demonstrating real-world engineering judgment and prioritization under resource constraints.\nA. Links:\nGitHub Repository B. Contact:\nProject Leader: Truong Quoc Tuan . Email: unviantruong26@gmail.com . WhatsApp: 0798806545 . --- "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Test the Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Create S3 bucket Navigate to S3 management console In the Bucket console, choose Create bucket In the Create bucket console Name the bucket: choose a name that hasn\u0026rsquo;t been given to any bucket globally (hint: lab number and your name) Leave other fields as they are (default) Scroll down and choose Create bucket Successfully create S3 bucket. Connect to EC2 with session manager For this workshop, you will use AWS Session Manager to access several EC2 instances. Session Manager is a fully managed AWS Systems Manager capability that allows you to manage your Amazon EC2 instances and on-premises virtual machines (VMs) through an interactive one-click browser-based shell. Session Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys.\nFirst cloud journey Lab for indepth understanding of Session manager.\nIn the AWS Management Console, start typing Systems Manager in the quick search box and press Enter: From the Systems Manager menu, find Node Management in the left menu and click Session Manager: Click Start Session, and select the EC2 instance named Test-Gateway-Endpoint. This EC2 instance is already running in \u0026ldquo;VPC Cloud\u0026rdquo; and will be used to test connectivity to Amazon S3 through the Gateway endpoint you just created (s3-gwe).\nSession Manager will open a new browser tab with a shell prompt: sh-4.2 $\nYou have successfully start a session - connect to the EC2 instance in VPC cloud. In the next step, we will create a S3 bucket and a file in it.\nCreate a file and upload to s3 bucket Change to the ssm-user\u0026rsquo;s home directory by typing cd ~ in the CLI Create a new file to use for testing with the command fallocate -l 1G testfile.xyz, which will create a file of 1GB size named \u0026ldquo;testfile.xyz\u0026rdquo;. Upload file to S3 bucket with command aws s3 cp testfile.xyz s3://your-bucket-name. Replace your-bucket-name with the name of S3 bucket that you created earlier. You have successfully uploaded the file to your S3 bucket. You can now terminate the session.\nCheck object in S3 bucket Navigate to S3 console. Click the name of your s3 bucket In the Bucket console, you will see the file you have uploaded to your S3 bucket Section summary Congratulation on completing access to S3 from VPC. In this section, you created a Gateway endpoint for Amazon S3, and used the AWS CLI to upload an object. The upload worked because the Gateway endpoint allowed communication to S3, without needing an Internet Gateway attached to \u0026ldquo;VPC Cloud\u0026rdquo;. This demonstrates the functionality of the Gateway endpoint as a secure path to S3 without traversing the Public Internet.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Review the structure and services in the project.\nUnderstand the flow of activities and the connection between system components.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study at the office. - Review the project structure. 10/11/2025 10/11/2025 3 - Examine the details of the services used in the project. 11/11/2025 11/11/2025 4 - Analyze the overall system workflow. 12/11/2025 12/11/2025 5 - Check the relationships and dependencies between services. 13/11/2025 13/11/2025 6 - Summarize the week’s findings and note unclear points. 14/11/2025 14/11/2025 7 - Attending the AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS event at the office. 14/11/2025 14/11/2025 Week 10 Achievements: Monday (10/11/2025):\nStudied at the office as planned.\nReviewed the overall project structure and understood the main components and folder organization.\nTuesday (11/11/2025):\nExamined the specific services implemented in the project.\nTook notes on the function and purpose of each service for future reference.\nWednesday (12/11/2025):\nAnalyzed the overall system workflow.\nUnderstood how modules interact and how data flows throughout the system.\nThursday (13/11/2025):\nChecked the relationships between services.\nIdentified dependencies and potential areas for optimization.\nFriday (14/11/2025):\nSummarized all progress made during the week.\nNoted unclear areas to clarify in the upcoming week.\nSaturday (15/11/2025):\nAttending the AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS event at the office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Execute the coding project.\nAttend AWS Events at the office.\nTasks to be carried out this week: Day Task Start Date Completion Date Resources Mon - Attend the AWS Cloud Mastery Series #2: DevOps on AWS event at the office. 17/11/2025 17/11/2025 Tue - Review the modules assigned for coding in detail. 18/11/2025 18/11/2025 Wed - Begin coding the initial parts. 19/11/2025 19/11/2025 Thu - Attend the AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer event at the office. 20/11/2025 20/11/2025 Fri - Continue coding. 21/11/2025 21/11/2025 Week 11 Achievements: Monday (17/11/2025):\nAttended the AWS Cloud Mastery Series #2: DevOps on AWS event at the office. Tuesday (18/11/2025):\nThoroughly reviewed the modules assigned by the leader for coding. Wednesday (19/11/2025):\nStarted coding the initial parts of the project. Thursday (20/11/2025):\nAttended the AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer event at the office. Friday (21/11/2025):\nContinued coding the assigned modules. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Code the assigned modules.\nLeader assigned the tasks: System Foundation \u0026amp; Testing.\nTasks to be Implemented This Week: Day Task Start Date Completion Date Resources Mon - Code the first assigned modules. 24/08/2025 25/08/2025 Tue - Continue coding. 25/08/2025 26/08/2025 Wed - Hand over the rough code to the leader for review and adjustments. 26/08/2025 27/08/2025 Thu - Begin Testing the completed modules. 27/08/2025 28/08/2025 Fri - Continue Testing. 28/08/2025 29/08/2025 Sat - Attend the AWS Cloud Mastery Series #3 event at the office: Following the AWS Well-Architected Security Pillar. 29/08/2025 29/08/2025 Week 12 Achieved Outcomes: Monday (24/11/2025):\nCoded the assigned modules. Tuesday (25/11/2025):\nContinued coding the assigned modules. Wednesday (26/11/2025):\nHanded over the rough code to the leader for review, correction, and supplementation within the code. Thursday (27/11/2025):\nPerformed Testing on the completed modules. Friday (28/11/2025):\nContinued Testing the modules. Saturday (29/11/2025):\nAttended the AWS Cloud Mastery Series #3: Following the AWS Well-Architected Security Pillar event at the office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.3-s3-vpc/",
	"title": "Access S3 from VPC",
	"tags": [],
	"description": "",
	"content": "Using Gateway endpoint In this section, you will create a Gateway eendpoint to access Amazon S3 from an EC2 instance. The Gateway endpoint will allow upload an object to S3 buckets without using the Public Internet. To create an endpoint, you must specify the VPC in which you want to create the endpoint, and the service (in this case, S3) to which you want to establish the connection.\nContent Create gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/3-translatedblog/",
	"title": "Blog Translated",
	"tags": [],
	"description": "",
	"content": "This section will list and introduce the blogs that I have translated.\nBlog 1 - AWS DMS validation: A custom serverless architecture. This blog presents how AWS designed a custom serverless architecture to automate and optimize the data validation process in AWS Database Migration Service (DMS). It provides a step-by-step guide on building a post-migration data verification system using AWS Lambda, Step Functions, S3, and DynamoDB — ensuring data integrity and accuracy between source and target. Additionally, the blog shares a reference architecture, implementation details of the validation workflow, and cost optimization tips for operating the system. Read full blogs on Google Docs\nBlog 2 - Transforming network operations with AI: How Swisscom built a network assistant using Amazon Bedrock. This blog describes how Swisscom — a major telecommunications provider in Europe — leveraged Amazon Bedrock to build an AI Network Assistant that supports network operations. The article explains how the system utilizes large language models (LLMs) to automatically analyze logs, diagnose issues, and suggest solutions for network engineers. In addition, it introduces the overall AI architecture, the model training and integration process, and the performance and accuracy improvements Swisscom achieved through Generative AI. Read full blogs on Google Docs\nBlog 3 - Introducing the latest AWS Well-Architected Framework: IoT Lens. This blog introduces the AWS Well-Architected IoT Lens, a new extension of the AWS Well-Architected Framework designed to help businesses architect and evaluate their IoT systems following AWS best practices. The article outlines the five core pillars — operational excellence, security, reliability, performance efficiency, and cost optimization — in the context of IoT, along with reference architectures, best practices, and automated assessment tools. It serves as a valuable resource for engineers aiming to ensure their IoT systems are secure, efficient, and scalable on the AWS platform. Read full blogs on Google Docs\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Test the Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Get the regional DNS name of S3 interface endpoint From the Amazon VPC menu, choose Endpoints.\nClick the name of newly created endpoint: s3-interface-endpoint. Click details and save the regional DNS name of the endpoint (the first one) to your text-editor for later use.\nConnect to EC2 instance in \u0026ldquo;VPC On-prem\u0026rdquo; Navigate to Session manager by typing \u0026ldquo;session manager\u0026rdquo; in the search box\nClick Start Session, and select the EC2 instance named Test-Interface-Endpoint. This EC2 instance is running in \u0026ldquo;VPC On-prem\u0026rdquo; and will be used to test connectivty to Amazon S3 through the Interface endpoint we just created. Session Manager will open a new browser tab with a shell prompt: sh-4.2 $\nChange to the ssm-user\u0026rsquo;s home directory with command \u0026ldquo;cd ~\u0026rdquo;\nCreate a file named testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file to the same S3 bucket we created in section 3.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; This command requires the \u0026ndash;endpoint-url parameter, because you need to use the endpoint-specific DNS name to access S3 using an Interface endpoint. Do not include the leading \u0026rsquo; * \u0026rsquo; when copying/pasting the regional DNS name. Provide your S3 bucket name created earlier Now the file has been added to your S3 bucket. Let check your S3 bucket in the next step.\nCheck Object in S3 bucket Navigate to S3 console Click Buckets Click the name of your bucket and you will see testfile2.xyz has been added to your bucket "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-s3-onprem/",
	"title": "Access S3 from on-premises",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will create an Interface endpoint to access Amazon S3 from a simulated on-premises environment. The Interface endpoint will allow you to route to Amazon S3 over a VPN connection from your simulated on-premises environment.\nWhy using Interface endpoint:\nGateway endpoints only work with resources running in the VPC where they are created. Interface endpoints work with resources running in VPC, and also resources running in on-premises environments. Connectivty from your on-premises environment to the cloud can be provided by AWS Site-to-Site VPN or AWS Direct Connect. Interface endpoints allow you to connect to services powered by AWS PrivateLink. These services include some AWS services, services hosted by other AWS customers and partners in their own VPCs (referred to as PrivateLink Endpoint Services), and supported AWS Marketplace Partner services. For this workshop, we will focus on connecting to Amazon S3. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Reflection Report: “AWS Cloud Day Vietnam 2025 \u0026amp; GenAI Track” Event: AWS Vietnam Cloud Day.\nDate: Thursday, September 18, 2025.\nTime: 9:00 AM – 17:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nPurpose of the Event. Introduce the latest technology trends from AWS, especially Generative AI.\nShare case studies from major enterprises in Vietnam and across the region.\nDiscuss leadership strategies and organizational management in the AI era.\nExplore best practices for security and real-world applications of AI Agents.\nSpeaker List. Morning: Hon. Government Speaker – Opening remarks.\nEric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS.\nDr. Jens Lottner – CEO, Techcombank.\nMs. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network.\nJaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS.\nJeff Johnson – Managing Director, ASEAN, AWS (Moderator).\nPanelists:\nVu Van – Co-founder \u0026amp; CEO, ELSA Corp\nNguyen Hoa Binh – Chairman, Nexttech Group\nDieter Botha – CEO, TymeX\nAfternoon: Kien Nguyen – Solutions Architect, AWS.\nMichael Armentano – Principal WW GTM Specialist, AWS.\nJun Kai Loke – AI/ML Specialist SA, AWS.\nTamelly Lim – Storage Specialist SA, AWS.\nBinh Tran – Senior Solutions Architect, AWS.\nTaiki Dang – Solutions Architect, AWS.\nKey Contents. Part 1: Main Sessions (AWS Cloud Day Vietnam). Opening \u0026amp; Keynote (Eric Yeo, AWS): Overview of AWS’s vision in Vietnam and Southeast Asia.\nCustomer Keynote 1 (Techcombank): Applying AI in finance to enhance operational efficiency and customer experience.\nCustomer Keynote 2 (U2U Network): Combining blockchain and AI to build a decentralized ecosystem.\nAWS Keynote (Jaime Valles): Regional tech trends and AWS’s strategies to empower innovation.\nPanel Discussion (Jeff Johnson + CEOs):\nLeadership must drive a culture of innovation.\nGenAI as a strategic enabler, not just a tool.\nChange management is critical when integrating AI.\nPart 2: GenAI Track. Building a Unified Data Foundation on AWS for AI and Analytics Workloads (Kien Nguyen):\nStrategies to build scalable and unified data foundations for AI \u0026amp; analytics.\nUtilizing AWS services for ingestion, storage, processing, and governance.\nBuilding the Future: GenAI Adoption and Roadmap on AWS (Jun Kai Loke \u0026amp; Tamelly Lim):\nOverview of the vision, trends, and development roadmap of GenAI on AWS.\nIntroduction to AWS services and initiatives supporting enterprise adoption.\nAI-Driven Development Lifecycle (AI-DLC) Shaping the Future of Software Implementation (Binh Tran):\nIntegrating AI into the entire software development lifecycle.\nCombining AI-assisted execution with human oversight to improve speed and quality.\nSecuring Generative AI Applications (Taiki Dang):\nAddressing GenAI security challenges: infrastructure, models, applications.\nSolutions: encryption, zero-trust architecture, continuous monitoring, fine-grained access control.\nBeyond Automation: AI Agents (Michael Armentano):\nAI Agents as “intelligent partners” beyond simple automation.\nCapable of learning, adapting, and executing complex tasks → driving exponential productivity.\nKeynotes. Eric Yeo (AWS): Vision for GenAI and its applications in Southeast Asia.\nTechcombank (Dr. Jens Lottner): Real-world AI adoption in financial services.\nU2U Network (Trang Phung): Synergy between blockchain and AI to build next-gen ecosystems.\nAWS (Jaime Valles): Regional innovation trends and enterprise transformation strategies.\nPanel Discussion: Navigating the GenAI Revolution. The leadership role in aligning organizations with GenAI.\nNurturing a culture of innovation and driving AI initiatives.\nManaging organizational change during AI integration.\nTechnical Insights \u0026amp; Best Practices. Securing Generative AI Applications (Taiki Dang):\nSecurity challenges in GenAI stacks (infrastructure, model, application).\nKey practices: encryption, zero-trust, continuous monitoring, fine-grained access.\nBeyond Automation: AI Agents (Michael Armentano):\nAI Agents as intelligent collaborators beyond traditional automation.\nSelf-learning and adaptive capabilities → significant productivity gains.\nKey Takeaways. Strategic Thinking. GenAI is not just a technology—it’s a catalyst for organizational transformation.\nLeadership must foster innovation and manage change effectively\nThe convergence of AI + Blockchain + Cloud opens new opportunities.\nTechnical \u0026amp; Security Knowledge. Security is fundamental for all GenAI applications.\nZero-trust architecture and continuous monitoring ensure integrity.\nUnderstanding security from infrastructure → model → application level is critical.\nLeveraging AI Agents. AI Agents surpass traditional automation through learning and decision-making.\nIntegration can significantly boost productivity and efficiency.\nApplications to Work. Propose internal workshops on AI Strategy \u0026amp; Change Management.\nPilot AI Agents in repetitive workflows to increase efficiency.\nReview AI workload security following zero-trust and encryption principles.\nIntegrate AI-driven insights into business data analytics.\nEvent Experience. Learning from Business Leaders. Case studies from Techcombank, U2U, ELSA, and Nexttech showcased multi-industry AI adoption.\nInsights into how CEOs handle organizational change and innovation.\nHands-on Technical Insights. Gained understanding of security architecture in GenAI deployments.\nRealized the transformative potential of AI Agents in next-level automation.\nNetworking \u0026amp; Collaboration. Engaged with AWS experts and industry executives.\nRecognized the importance of collaboration between business and technology in the GenAI era.\nLessons Learned. Leadership plays a key role in enabling GenAI adoption.\nBalancing security, operational efficiency, and innovation is crucial.\nAI Agents will become an inevitable part of future workflows.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: AI/ML/GenAI on AWS Event: AWS Cloud Mastery Series #1 : AI/ML/GenAI on AWS\nDate: Saturday, November 15, 2025.\nTime: 8:30 AM – 11:30 AM.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide foundational to advanced knowledge on AI/ML and Generative AI (GenAI) services on the Amazon Web Services (AWS) platform.\n1. Welcome \u0026amp; Context (8:00 – 8:30 AM) The event kicked off with participant registration and networking among professionals and attendees.\nAn overview of learning objectives was provided, directing the content to focus on practical AWS tools.\nAn introduction to the AI/ML landscape in Vietnam highlighted key trends and major challenges in the region.\n2. AWS AI/ML Platform Overview (8:30 – 10:00 AM) This segment focused on Amazon SageMaker, the end-to-end Machine Learning (ML) platform from AWS:\nML Lifecycle: Attendees learned about the crucial stages, from data preparation and labeling to efficient model training, tuning, and deployment.\nIntegrated MLOps: Introduction to the built-in MLOps capabilities in SageMaker, which help automate and manage the model lifecycle in production environments.\nLive Demo: SageMaker Studio: A live demonstration of SageMaker\u0026rsquo;s integrated development environment (IDE), illustrating how data scientists can work effectively on the platform.\n10:00 – 10:15 AM | Coffee Break (15 minutes) 3. Generative AI (GenAI) with Amazon Bedrock (10:15 AM – 11:30 AM) After the coffee break, the focus shifted to GenAI via Amazon Bedrock, the hub for Foundation Models (FMs):\nFoundation Models: Analysis and comparison of leading FMs like Claude, Llama, and Titan, along with guidance on selecting the appropriate model for specific tasks.\nPrompt Engineering: Learning essential and advanced techniques, including Chain-of-Thought reasoning and Few-shot learning to optimize FM output.\nRetrieval-Augmented Generation (RAG): Introduction to the RAG architecture and the role of integrating a Knowledge Base to feed the FM proprietary information, enhancing accuracy.\nBedrock Agents \u0026amp; Guardrails: Exploration of how Bedrock Agents enable the creation of automated multi-step workflows. Concurrently, learning about Guardrails to ensure safety and content filtering against harmful outputs.\nLive Demo: A practical demonstration of building a simple GenAI chatbot using Bedrock components.\n11:30 AM | Finish \u0026amp; Lunch Lunch Break (Self-arranged) Event Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: FOCUS ON AWS BEDROCK AGENT AND AGENTIC WORKFLOW Event: Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock.\nDate: Friday, December 5, 2025.\nTime: 8:30 AM – 12:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide in-depth knowledge on building and operating automated workflows (Agentic Workflows) using AWS Bedrock Agent and to introduce optimization solutions from the partner, CloudThinker.\nPROGRAM SUMMARY Time Topic Speaker Key Highlights 9:00 - 9:10 Opening Nguyen Gia Hung, Head of Solutions Architect Set the goals and context for the event. 9:10 - 9:40 AWS Bedrock Agent Core Kien Nguyen, Solutions Architect Analysis of the architecture, core features, and operational mechanism of Bedrock Agent. 9:40 - 10:00 [Use Case] Building Agentic Workflow on AWS Viet Pham, Founder cum CEO Presented a real-world example of deploying automated workflows on AWS. 10:00 - 10:10 CloudThinker Introduction Thang Ton, Co-founder \u0026amp; COO Introduced the company and its solution focused on GenAI optimization. 10:10 - 10:40 CloudThinker Agentic Orchestration, Context Optimization on Amazon Bedrock (L300) Henry Bui, Head of Engineering Deep dive into Agent coordination techniques and context optimization for Bedrock. 10:40 - 11:00 Tea Break \u0026amp; Networking Opportunity for discussion and relaxation. 11:00 - 12:00 CloudThinker Hack: Hands-on Workshop Kha Van Direct practical session on building an Agentic solution. 12:00 Networking \u0026amp; Lunch Buffet IN-DEPTH KNOWLEDGE GAINED 1. Core Architecture of AWS Bedrock Agent The presentation by Mr. Kien Nguyen clarified the role of Bedrock Agent as a powerful tool to automate complex tasks by connecting Foundation Models (FM) with business systems and APIs.\nOperational Mechanism: The Agent uses the FM\u0026rsquo;s reasoning capability to analyze the user\u0026rsquo;s request, determine the necessary steps, and call Tools (Action Groups) to complete the task.\nKey Benefit: Reduces the programming effort for multi-step workflows and ensures safety (safety guardrails) when accessing internal data or systems.\n2. Practical Application: Building Agentic Workflows The Use Case from Mr. Viet Pham illustrated how to transform manual, sequential processes into automated, Agent-driven workflows.\nThe crucial point is the clear definition of system capabilities and APIs so the Agent can accurately understand and utilize them.\n3. Optimizing Agentic Workflows with CloudThinker CloudThinker\u0026rsquo;s session focused on addressing advanced (L300) challenges when operating Agents:\nAgentic Orchestration: Coordination strategies to manage multiple Agents or complex steps, ensuring consistency and performance.\nContext Optimization: Techniques for optimizing the context passed to the FM (e.g., RAG optimization, context window management) to reduce token costs and improve the Agent\u0026rsquo;s accuracy/reasoning capability.\nThis is key to deploying cost-effective and reliable Agentic applications in an enterprise environment.\n4. In-Depth Hands-on Workshop The CloudThinker Hack session, led by Kha Van, provided a valuable opportunity for attendees to:\nDirectly configure and deploy a simple Agent on Amazon Bedrock.\nApply optimization techniques for context and orchestration from CloudThinker to the built workflow.\nThe practical session reinforced theoretical knowledge and provided a better understanding of the technical challenges when moving Agents to production.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: DEVOPS ON AWS Event Name: AWS Cloud Mastery Series #2 : DevOps on AWS.\nDate: Monday, November 17, 2025.\nTime: 8:30 AM – 5:00 PM.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide comprehensive knowledge on DevOps Culture, principles, performance metrics, and the suite of AWS DevOps services for building CI/CD pipelines, IaC, and Observability.\nMORNING SESSION (8:30 AM – 12:00 PM): CI/CD \u0026amp; INFRASTRUCTURE AS CODE 1. Welcome \u0026amp; DevOps Mindset (8:30 – 9:00 AM) The event began with a quick recap from the previous AI/ML session, setting the context for moving models/applications into production. The focus was on DevOps culture and principles, emphasizing collaboration between Development (Dev) and Operations (Ops). Introduction to key performance metrics such as DORA (Deployment Frequency, Lead Time for Changes, MTTR, Change Failure Rate) and MTTR (Mean Time To Recovery). 2. AWS DevOps Services – Building the CI/CD Pipeline (9:00 – 10:30 AM) This section delved into the AWS CodeFamily suite of tools to automate Continuous Integration (CI) and Continuous Deployment (CD):\nSource Control: Using AWS CodeCommit and discussing source code management strategies like GitFlow and Trunk-based. Build \u0026amp; Test: Configuring CodeBuild to automate compilation and running testing pipelines. Deployment: Analyzing advanced deployment strategies with CodeDeploy, including Blue/Green, Canary, and Rolling updates. Orchestration: Utilizing CodePipeline to automate the entire process from commit to production. Demo: A visual demonstration of a complete CI/CD pipeline on AWS. 3. Infrastructure as Code (IaC) (10:45 AM – 12:00 PM) IaC is the foundation of modern DevOps, ensuring environment consistency and reproducibility:\nAWS CloudFormation: Learning about Templates, Stacks, and how to use Drift Detection to identify discrepancies between the actual state and the source code. AWS CDK (Cloud Development Kit): Introducing CDK as a more modern approach, using familiar programming languages (TypeScript, Python,\u0026hellip;) to define infrastructure via Constructs and reusable patterns. Demo \u0026amp; Discussion: Demonstrating infrastructure deployment using both CloudFormation and CDK, along with a discussion on criteria for choosing the right IaC tool. AFTERNOON SESSION (1:00 PM – 5:00 PM): CONTAINER, OBSERVABILITY \u0026amp; BEST PRACTICES 4. Container Services on AWS (1:00 – 2:30 PM) Docker Fundamentals: Review of basic concepts related to Microservices and Containerization. Amazon ECR (Elastic Container Registry): The service for storing container images, including image scanning features and lifecycle policies. Amazon ECS \u0026amp; EKS: Comparing the two main container orchestration services: ECS (simpler, AWS integrated) and EKS (Kubernetes-based). Analysis of deployment and scaling strategies. AWS App Runner: A simplified solution for container deployment, focusing on code over infrastructure. Demo \u0026amp; Case Study: Illustrating microservices architecture deployment and comparing the services. 5. Monitoring \u0026amp; Observability (2:45 – 4:00 PM) CloudWatch: The core tool for collecting metrics, logs, alarms, and dashboards across the entire AWS ecosystem. AWS X-Ray: Provides Distributed Tracing to track request flow across microservices, helping to identify bottlenecks and performance issues. Demo: Setting up a comprehensive observability system (Full-stack observability). Best Practices: Best practices for Alerting, dashboards, and the on-call process. 6. DevOps Best Practices \u0026amp; Case Studies (4:00 – 4:45 PM) Advanced Deployment Strategies: Discussion on Feature flags and A/B testing within the deployment pipeline. Automated testing and deep integration with CI/CD. Incident Management: Managing incidents and the importance of Postmortems for learning and improvement. Case Studies: Lessons learned from startups and large enterprises that have undergone successful DevOps transformations. 7. Q\u0026amp;A \u0026amp; Wrap-up (4:45 – 5:00 PM) Addressing in-depth questions. Providing information on DevOps career pathways and relevant AWS certifications. Event Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: THE AWS WELL-ARCHITECTED SECURITY PILLAR Event: AWS Cloud Mastery Series #3: Following the AWS Well-Architected Security Pillar.\nDate: Saturday, November 29, 2025.\nTime: 8:30 AM – 12:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide in-depth knowledge on the 5 pillars of the Security Pillar within the Well-Architected Framework, including core principles, services, and defense strategies.\nPROGRAM SUMMARY Time Topic Key Focus 8:30 – 8:50 Opening \u0026amp; Security Foundation Role of the Security Pillar, Shared Responsibility Model, and top cloud threats in Vietnam. 8:50 – 9:30 Pillar 1: Identity \u0026amp; Access Management (IAM) Modern IAM Architecture (Users, Roles, Policies), IAM Identity Center, SCP, MFA, and Access Analyzer Demo. 9:30 – 9:55 Pillar 2: Detection Continuous monitoring with CloudTrail, GuardDuty, Security Hub, and the Detection-as-Code model. 10:10 – 10:40 Pillar 3: Infrastructure Protection Network security (VPC segmentation, SG vs NACL), WAF, Network Firewall, and Workload security. 10:40 – 11:10 Pillar 4: Data Protection Encryption (at-rest \u0026amp; in-transit), Key Management (KMS), Secrets Management (Secrets Manager), and Data Classification. 11:10 – 11:40 Pillar 5: Incident Response AWS IR lifecycle, Playbooks (Key Compromise, S3 Exposure), and automated response (Auto-response). 11:40 – 12:00 Wrap-Up \u0026amp; Q\u0026amp;A Common pitfalls and the Security Specialty learning roadmap. IN-DEPTH KNOWLEDGE BY THE 5 PILLARS 1. Security Foundation \u0026amp; Core Principles Core Principles: Emphasis on the necessity of Least Privilege, Zero Trust (never trust, always verify), and Defense in Depth (layered defense).\nShared Responsibility Model: Clarifying the boundary of responsibility: AWS is responsible for the security of the Cloud (infrastructure, physical), while the Customer is responsible for security in the Cloud (data, IAM, configuration).\n2. Pillar 1: Identity \u0026amp; Access Management (IAM) Modern Architecture: Avoid using long-term credentials (long-lived Access Keys) for users. Prioritize Roles for services and IAM Identity Center (SSO) for users.\nMulti-Account Control: Apply Service Control Policies (SCPs) at the AWS Organizations level and Permission Boundaries to set maximum limits for delegated permissions.\nMini Demo: Demonstration of using Access Analyzer and the policy simulator tool to verify and validate access rights before deployment.\n3. Pillar 2: Detection Continuous Monitoring: Utilize CloudTrail (at the Organization level) to log all API actions, GuardDuty for ML-powered abnormal threat detection, and Security Hub to aggregate findings.\nDetection-as-Code: Defining detection rules as code (e.g., Lambda, CloudFormation) to automate deployment and management.\n4. Pillar 3: Infrastructure Protection Network Segmentation: Separate application tiers (Web, App, DB) using VPC segmentation. Clearly distinguish the roles of Security Groups (stateful) and NACLs (stateless).\nPerimeter Defense: Deploy WAF (Web Application Firewall) and Shield to protect applications against DDoS and Layer 7 attacks.\n5. Pillar 4: Data Protection Encryption: Ensure data is encrypted both at-rest (stored in S3, EBS, RDS) and in-transit (transmitted via TLS/SSL).\nKey and Secrets Management: Use KMS (Key Management Service) to manage primary encryption keys, control key policies, and key rotation. Use Secrets Manager to store and automatically rotate secrets (database passwords, API keys).\n6. Pillar 5: Incident Response IR Lifecycle: Guidance on adhering to the AWS standard lifecycle (Prepare, Detect, Respond, Recover).\nResponse Automation: Develop automated Playbooks using Lambda or Step Functions for common incidents like compromised IAM keys or EC2 malware detection. Key steps include Snapshot, isolation, and evidence collection.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: AWS FOR SAP USING GENERATIVE AI Time: 1:00 PM - 5:00 PM.\nSpeaker: Nonthakorn Junthapol.\nTopic: AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To explore how Generative Artificial Intelligence (GenAI) can optimize and modernize the SAP environment, focusing on enhancing ABAP development productivity through Amazon Q Developer.\nCONTEXT AND GOALS OF GENAI IN SAP 1. Modernizing SAP on AWS The event established the foundation by affirming AWS\u0026rsquo;s role as the preferred cloud platform for SAP S/4HANA systems (including the RISE with SAP model).\nDiscussion covered traditional challenges in the SAP environment: the complexity of Legacy ABAP code, the need for modernization (e.g., migrating to S/4HANA), and slow development speed.\n2. The Role of Generative AI GenAI was introduced as a strategic tool to overcome these challenges, especially in code automation, refactoring, and data interaction.\nServices like Amazon Bedrock (or custom models on SageMaker) can be used to analyze unstructured SAP data (e.g., PO documents, Invoices) after extraction via AWS.\nDEEP DIVE: AMAZON Q DEVELOPER AND ABAP CAPABILITIES 3. Introducing Amazon Q Developer Amazon Q Developer is an AI assistant designed to accelerate software development, customized to understand the context of AWS infrastructure and APIs.\nA key highlight is its ability to interact using natural language to solve technical issues and generate code.\n4. Boosting Productivity with SAP ABAP The core focus of the event delved into how Amazon Q directly supports ABAP developers:\nAmazon Q Capability Application in ABAP Value Proposition Code Generation Quickly creating ABAP code snippets for BAPIs, Function Modules, or standard ALV reports. Increases initial coding speed. Code Explanation Analyzing and explaining complex or sparsely used legacy ABAP code segments. Reduces maintenance time and code learning curve. Refactoring \u0026amp; Modernization Supporting the conversion of old ABAP code to more modern object-oriented (OOP) syntax and principles (e.g., preparing for S/4HANA). Lowers the risk and cost of system migration/upgrade. Troubleshooting Suggesting solutions and debugging guidance based on error messages in the SAP environment. Minimizes Mean Time To Recovery (MTTR). 5. Integration Mechanism and Security Amazon Q functions as an abstraction layer, accessing ABAP source code through authorized connections (potentially via AWS Connector tools or integration with the development environment).\nData Security: It was emphasized that ABAP source code data is processed securely and is not used to train the underlying Amazon Q model, ensuring the privacy and security of enterprise intellectual property.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/",
	"title": "Event Participants",
	"tags": [],
	"description": "",
	"content": "During my internship, I participated in six events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Cloud Day Vietnam 2025 \u0026amp; GenAI Track.\nTime: 09:00 AM - 17:00 PM, Thursday December 18, 2025.\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City.\nRole: Attendee.\nEvent 2 Event Name: AWS Cloud Mastery Series #1 : AI/ML/GenAI on AWS\nTime: 8:30 AM – 11:30 AM, Saturday, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock\nTime: 9:00 AM - 12:00 PM ; Friday, December 5, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #2 : DevOps on AWS\nTime: 8:30 AM – 17:00 PM ; Monday, November 17, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #3 : Security on AWS\nTime: 8:30 AM – 12:00 AM ; Saturday, November 29, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 6 Event Name: AWS for SAP Using Generative AI : SAP ABAP capabilities and Amazon Q Developer\nTime: 13:00 PM – 17:00 PM ; Thursday, November 20, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "On-premises DNS Simulation",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoints have a fixed IP address in each Availability Zone where they are deployed, for the life of the endpoint (until it is deleted). These IP addresses are attached to Elastic Network Interfaces (ENIs). AWS recommends using DNS to resolve the IP addresses for endpoints so that downstream applications use the latest IP addresses when ENIs are added to new AZs, or deleted over time.\nIn this section, you will create a forwarding rule to send DNS resolution requests from a simulated on-premises environment to a Route 53 Private Hosted Zone. This section leverages the infrastructure deployed by CloudFormation in the Prepare the environment section.\nCreate DNS Alias Records for the Interface endpoint Navigate to the Route 53 management console (Hosted Zones section). The CloudFormation template you deployed in the Prepare the environment section created this Private Hosted Zone. Click on the name of the Private Hosted Zone, s3.us-east-1.amazonaws.com: Create a new record in the Private Hosted Zone: Record name and record type keep default options Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor (you saved when doing section 4.3) Click Add another record, and add a second record using the following values. Click Create records when finished to create both records. Record name: *. Record type: keep default value (type A) Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor The new records appear in the Route 53 console:\nCreate a Resolver Forwarding Rule Route 53 Resolver Forwarding Rules allow you to forward DNS queries from your VPC to other sources for name resolution. Outside of a workshop environment, you might use this feature to forward DNS queries from your VPC to DNS servers running on-premises. In this section, you will simulate an on-premises conditional forwarder by creating a forwarding rule that forwards DNS queries for Amazon S3 to a Private Hosted Zone running in \u0026ldquo;VPC Cloud\u0026rdquo; in-order to resolve the PrivateLink interface endpoint regional DNS name.\nFrom the Route 53 management console, click Inbound endpoints on the left side bar In the Inbound endpoints console, click the ID of the inbound endpoint Copy the two IP addresses listed to your text editor From the Route 53 menu, choose Resolver \u0026gt; Rules, and click Create rule: In the Create rule console: Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: Enter both IP addresses from your text editor (inbound endpoint addresses) and then click Submit You have successfully created resolver forwarding rule.\nTest the on-premises DNS Simulation Connect to Test-Interface-Endpoint EC2 instance with Session manager Test DNS resolution. The dig command will return the IP addresses assigned to the VPC Interface endpoint running in VPC Cloud (your IP\u0026rsquo;s will be different): dig +short s3.us-east-1.amazonaws.com The IP addresses returned are the VPC endpoint IP addresses, NOT the Resolver IP addresses you pasted from your text editor. The IP addresses of the Resolver endpoint and the VPC endpoint look similar because they are all from the VPC Cloud CIDR block.\nNavigate to the VPC menu (Endpoints section), select the S3 Interface endpoint. Click the Subnets tab and verify that the IP addresses returned by Dig match the VPC endpoint: Return to your shell and use the AWS CLI to test listing your S3 buckets: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Terminate your Session Manager session: In this section you created an Interface endpoint for Amazon S3. This endpoint can be reached from on-premises through Site-to-Site VPN or AWS Direct Connect. Route 53 Resolver outbound endpoints simulated forwarding DNS requests from on-premises to a Private Hosted Zone running the cloud. Route 53 inbound Endpoints recieved the resolution request and returned a response containing the IP addresses of the VPC interface endpoint. Using DNS to resolve the endpoint IP addresses provides high availability in-case of an Availability Zone outage.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "When you create an interface or gateway endpoint, you can attach an endpoint policy to it that controls access to the service to which you are connecting. A VPC endpoint policy is an IAM resource policy that you attach to an endpoint. If you do not attach a policy when you create an endpoint, AWS attaches a default policy for you that allows full access to the service through the endpoint.\nYou can create a policy that restricts access to specific S3 buckets only. This is useful if you only want certain S3 Buckets to be accessible through the endpoint.\nIn this section you will create a VPC endpoint policy that restricts access to the S3 bucket specified in the VPC endpoint policy.\nConnect to an EC2 instance and verify connectivity to S3 Start a new AWS Session Manager session on the instance named Test-Gateway-Endpoint. From the session, verify that you can list the contents of the bucket you created in Part 1: Access S3 from VPC: aws s3 ls s3://\\\u0026lt;your-bucket-name\\\u0026gt; The bucket contents include the two 1 GB files uploaded in earlier.\nCreate a new S3 bucket; follow the naming pattern you used in Part 1, but add a \u0026lsquo;-2\u0026rsquo; to the name. Leave other fields as default and click create Successfully create bucket\nNavigate to: Services \u0026gt; VPC \u0026gt; Endpoints, then select the Gateway VPC endpoint you created earlier. Click the Policy tab. Click Edit policy. The default policy allows access to all S3 Buckets through the VPC endpoint.\nIn Edit Policy console, copy \u0026amp; Paste the following policy, then replace yourbucketname-2 with your 2nd bucket name. This policy will allow access through the VPC endpoint to your new bucket, but not any other bucket in Amazon S3. Click Save to apply the policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Successfully customize policy\nFrom your session on the Test-Gateway-Endpoint instance, test access to the S3 bucket you created in Part 1: Access S3 from VPC aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy:\nReturn to your home directory on your EC2 instance cd~ Create a file fallocate -l 1G test-bucket2.xyz Copy file to 2nd bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; This operation succeeds because it is permitted by the VPC endpoint policy.\nThen we test access to the first bucket by copy the file to 1st bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy.\nPart 3 Summary: In this section, you created a VPC endpoint policy for Amazon S3, and used the AWS CLI to test the policy. AWS CLI actions targeted to your original S3 bucket failed because you applied a policy that only allowed access to the second bucket you created. AWS CLI actions targeted for your second bucket succeeded because the policy allowed them. These policies can be useful in situations where you need to control access to resources through VPC endpoints.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Secure Hybrid Access to S3 using VPC Endpoints Overview AWS PrivateLink provides private connectivity to AWS services from VPCs and your on-premises networks, without exposing your traffic to the Public Internet.\nIn this lab, you will learn how to create, configure, and test VPC endpoints that enable your workloads to reach AWS services without traversing the Public Internet.\nYou will create two types of endpoints to access Amazon S3: a Gateway VPC endpoint, and an Interface VPC endpoint. These two types of VPC endpoints offer different benefits depending on if you are accessing Amazon S3 from the cloud or your on-premises location\nGateway - Create a gateway endpoint to send traffic to Amazon S3 or DynamoDB using private IP addresses.You route traffic from your VPC to the gateway endpoint using route tables. Interface - Create an interface endpoint to send traffic to endpoint services that use a Network Load Balancer to distribute traffic. Traffic destined for the endpoint service is resolved using DNS. Content Workshop overview Prerequiste Access S3 from VPC Access S3 from On-premises VPC Endpoint Policies (Bonus) Clean up "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.6-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/6-self-evaluation/",
	"title": "Self-Evaluation",
	"tags": [],
	"description": "",
	"content": "During my internship at [Amazon Web Service] from [September] to [December], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in AWS Cloud Heath Dashboard, through which I improved my skills in programming, reporting, communication.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality. ☐ ☐ ✅ 2 Ability to learn Ability to absorb new knowledge and learn quickly. ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions. ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality. ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes. ☐ ✅ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself. ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly. ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams. ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment. ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity. ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team. ☐ ✅ ☐ 12 Overall General evaluation of the entire internship period. ☐ ✅ ☐ Needs Improvement. Strengthen discipline and strictly comply with the rules and regulations of the company or any organization.\nImprove problem-solving thinking.\nEnhance communication skills in both daily interactions and professional contexts, including handling situations effectively.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/7-feedback/",
	"title": "Feedback",
	"tags": [],
	"description": "",
	"content": " Here, you can freely share your personal opinions and experiences during the First Cloud Journey program to help the FCJ team improve any shortcomings based on the following categories:\nOverall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What are you most satisfied with during your internship?\n→ The mentors and team admins were always supportive and willing to help, which made tasks much easier to understand and complete.\nWhat do you think the company should improve for future interns?\n→ The onboarding process could be improved to help interns get familiar with the environment and their tasks more quickly.\nIf you were to recommend this internship to your friends, would you do so? Why?\n→ Yes. The working environment is friendly, supportive, and provides good learning opportunities for both technical and soft skills.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? → No, I don\u0026rsquo;t have any thing to say. It\u0026rsquo;s perfect.\nWould you like to continue this program in the future? → Yes. I would be happy to join future programs if given the opportunity.\nOther comments (feel free to share): → Everything was well-organized, and the team was very helpful. Thank you for the experience.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]