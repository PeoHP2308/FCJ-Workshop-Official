[
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Nguyen Truong Huy.\nPhone Number: 0827338992.\nEmail: truonghuy20203@gmail.com .\nUniversity: FPT University.\nMajor: Information System.\nClass: AWS082025.\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern.\nInternship Duration: From September to December 2025.\nReport Content: Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Build a Basic AWS VPC with Public \u0026amp; Private Subnets In this workshop, you will build a simple network foundation in AWS using Amazon VPC (Virtual Private Cloud). The goal is to help beginners understand how networking works in the cloud, and how different components connect together to form a secure, controlled environment.\nYou will create a VPC with two subnets:\nA Public Subnet – allows resources (like EC2 instances) to access the Internet directly. A Private Subnet – isolated from the public Internet by default for better security. To enable the private subnet to download packages and access online services without being exposed publicly, you will configure:\nAn Internet Gateway (IGW) – allows public subnet traffic to flow to/from the Internet. A NAT Gateway – lets instances in the private subnet access the Internet indirectly, without assigning a public IP. By the end, you will spin up two EC2 instances — one in each subnet — and test communication between them while observing the role of routing and gateways.\nThis hands-on workshop teaches essential AWS networking fundamentals through guided steps and console navigation. Perfect for beginners who want to build confidence working with VPCs.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Connect and get acquainted with members of the First Cloud Journey (FCJ).\nUnderstand basic AWS services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get to know FCJ members. - Read and note the rules and regulations of the internship unit. 08/09/2025 09/09/2025 3 - Learn about Cloud Computing. 09/09/2025 10/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Study at the office. - Continue learning about Cloud Computing. - First random blog translation attempt. 10/09/2025 11/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Learn about basic VPC concepts: + Subnet. + Route Table. + Security. - Watch labs 1 on AWS. 11/09/2025 13/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Continue learning about Cloud Computing on YouTube. 12/09/2025 14/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 1 Achievements Monday (08/09/2025):\nConnected and got acquainted with members of the First Cloud Journey (FCJ).\nRead, took notes, and understood the rules and regulations of the internship unit.\nTuesday (09/09/2025):\nStudied and understood the basic concepts of Cloud Computing. Wednesday (10/09/2025):\nGo to the office for studying.\nAttended the internship office and got familiar with the working environment.\nContinued learning about Cloud Computing.\nFirst random AWS blog translation attempt.\nThursday (11/09/2025):\nLearned about VPC (Virtual Private Cloud) and its fundamental components:\nSubnet.\nRoute Table.\nSecurity Group.\nWatched and took notes on AWS Lab 1 about network configuration.\nFriday (12/09/2025):\nContinued learning about Cloud Computing through YouTube.\nUnderstanding of cloud infrastructure operations and AWS benefits.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Practice using AWS technologies.\nUnderstand basic AWS services.\nTasks to be carried out this week Day Task Start Date Completion Date Reference Material 2 - Continue learning AWS on YouTube. - Explore and understand AWS technologies. 15/09/2025 15/09/2025 3 - Attend a team meeting to discuss project ideas, programming languages, and technologies to be used. 16/09/2025 16/09/2025 4 - Learn AWS through YouTube videos. 17/09/2025 17/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Attend the AWS Cloud Day Vietnam event at the office. 18/09/2025 18/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Learn how to use AWS technologies. 19/09/2025 21/09/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 2 Achievements: Monday (15/09/2025):\nContinued learning AWS on YouTube, reinforcing basic concepts of cloud computing.\nExplored core AWS technologies and services, such as Compute, Storage, Database, and Networking.\nTuesday (16/09/2025):\nParticipated in a team meeting to discuss project ideas.\nAgreed on the programming language, technologies, and AWS services to be used during project development.\nWednesday (17/09/2025):\nContinued studying AWS content through instructional videos.\nBecame familiar with the AWS Management Console and how to access different services.\nThursday (18/09/2025):\nAttended the AWS Cloud Day Vietnam 2025 event at the office.\nListened to AWS experts discuss Cloud Computing trends, AI/ML, and Digital Transformation in businesses.\nFriday (19/09/2025):\nLearned how to use and work with AWS technologies.\nBegan getting familiar with deploying and managing basic AWS services.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Understand how to use AWS technologies.\nLearn basic AWS services, including how to use the Console and CLI.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS through YouTube. 22/09/2025 22/09/2025 3 - Try to translate the second random blog. 23/09/2025 23/09/2025 Youtube: AWS Cloud Journey 4 - Learn about Compute VM on AWS. - Study EC2 Instance Types - Including: + Amazon Elastic Compute Cloud (EC2). + Amazon Lightsail. 24/09/2025 24/09/2025 https://aws.amazon.com/ec2/instance-types/?ncl=h_is/ 5 - Study basic EC2 Concepts:\n+ Amazon EFS/FSX. + AWS Application Migration Service (MGN). 25/09/2025 27/09/2025 https://aws.amazon.com/ec2/instance-types/?ncl=h_is/ 6 - Practice: + Create an EC2 instance. + Create a database. 26/09/2025 28/09/2025 Week 3 Achievements: Monday (22/09/2025):\nLearn the basic concepts of AWS through YouTube tutorials.\nGained an overview of AWS core services.\nTuesday (23/09/2025):\nSecond random AWS blog translation attempt. Wednesday (24/09/2025):\nStudied Compute VM on AWS.\nExplored the Compute service group on AWS, including:\nAmazon EC2.\nAmazon Lightsail.\nThursday (25/09/2025):\nUnderstanding of Basic EC2 concepts.\nLearned how to choose the right instance type.\nStudied the following services:\nAmazon EFS / FSX.\n**AWS Application Migration Service (MGN).\n→ Gained comprehensive knowledge of EC2 instance types.\nFriday (26/09/2025):\nSuccessfully completed hands-on practice:\nCreated an EC2 instance.\nCreated a database on AWS.\nBecame familiar with using the AWS Management Console.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Create an AWS account.\nPractice using AWS modules and core services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create an AWS account. - Successfully activate $200 free credits. 29/10/2025 29/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 3 - Perform basic operations on AWS: + Create an EC2 Instance. + Learn about Billing \u0026amp; Cost Management.\n+ Explore Aurora \u0026amp; RDS. 30/10/2025 01/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 4 - Explore and practice with EC2. - Get familiar with Billing and Cost Management. - Install and configure AWS CLI for basic resource management. 01/10/2025 02/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 5 - Learn about AWS Private Certificate Authority. - Understand how to manage Databases on AWS. - Translate 3 assigned blog post. 02/10/2025 02/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] 6 - Study AWS Lambda and Amazon Bedrock. - Practice deploying serverless services. - Review basic operations on Console \u0026amp; CLI. - Successfully push the project folder to GitHub. 03/10/2025 05/10/2025 [https://us-east-2.console.aws.amazon.com/console/home?/] Week 4 Achievements Monday (29/09/2025):\nSuccessfully created an AWS Free Tier account.\nCompleted activation of the $200 free credit.\nTuesday (30/09/2025):\nLaunched and operated an EC2 Instance.\nBecame familiar with Billing \u0026amp; Cost Management.\nWednesday (01/10/2025):\nPracticed more deeply with EC2.\nUnderstood and used key features in Billing and Cost Management.\nInstalled and configured AWS CLI for managing basic resources.\nThursday (02/10/2025):\nLearned about AWS Private Certificate Authority.\nBecame familiar with database management in AWS.\nTranslate 3 assigned blog post.\nFriday (03/10/2025):\nStudied and practiced with AWS Lambda and Amazon Bedrock.\nExperimented with serverless deployment.\nPracticed essential operations on Console \u0026amp; CLI.\nSuccessfully pushed the project folder to GitHub.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Continue learning AWS on YouTube.\nUnderstand core AWS services.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study at the office. - Learn Module 03: Amazon Elastic Compute Cloud (EC2): + AMI / Backup / Key Pair. + Elastic block store. + User data. + Meta data. 06/10/2025 06/10/2025 Youtube: AWS Cloud Journey 3 - Continue studying Amazon EC2: + EC2 auto scaling. + EFS/FSX. + Lightsail. + MGN. 07/10/2025 07/10/2025 Youtube: AWS Cloud Journey 4 - Study at the office. - Translate and edit AWS blog content. 08/10/2025 08/10/2025 Youtube: AWS Cloud Journey 5 - Study AWS Storage Services: + Amazon Simple Storage. Service - S3. + Amazon Storage Gateway. + Snow Family. + Disaster Recovery on AWS. + AWS Backup. - Complete and review translated blog. 09/10/2025 11/10/2025 Youtube: AWS Cloud Journey 6 - Continue Module 04: + Access Point. + Storage Class. + S3 Static Website \u0026amp; CORS. + Control Access. + Object Key \u0026amp; Performance. + Glacier. 10/10/2025 12/10/2025 Youtube: AWS Cloud Journey Week 5 Achievements Monday (06/10/2025):\nGo to the office for studying.\nLearned and practiced with Amazon EC2: created and configured EC2 instances.\nPracticed AMI, EBS, User Data, and Meta Data.\nGenerated and used Key Pairs for secure access to instances.\nTuesday (07/10/2025):\nGained knowledge about EC2 Auto Scaling.\nStudied additional AWS storage options: EFS and FSx.\nExplored Lightsail and MGN for lightweight and migration use cases.\nWednesday (08/10/2025):\nGo to the office for studying.\nTranslated and edited an AWS blog.\nThursday (09/10/2025):\nExplored AWS Storage Services in depth:\nAmazon S3: Created buckets, uploaded files, configured ACLs, Bucket Policies, CORS, and Static Website Hosting.\nAmazon Storage Gateway: Connected on-premises data with AWS cloud storage.\nAWS Snow Family: Learned about large-scale data migration solutions.\nAWS Backup: Studied centralized data backup and recovery processes.\nDisaster Recovery (DR) on AWS: Understood strategies for resilience.\nCompleted and reviewed translated blog.\nFriday (10/10/2025):\nContinued studying Module 04: learned about Access Point and Storage Class in S3.\nPracticed Static Website Hosting and CORS configuration on S3.\nStudied Object Key, storage performance, and Amazon Glacier for long-term data archiving.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Continue watching AWS service tutorials on YouTube.\nPrepare knowledge for the midterm exam.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Watch Module 5 – Shared Responsibility Model. - Study Amazon Identity and Access Management (IAM). 13/10/2025 13/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Continue Module 5: + Watch Amazon Identity and access management. + Watch Amazon Cognito. + AWS Organization. 14/10/2025 14/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Watch AWS Identity Center. - Watch Amazon Key Management Service. - Watch AWS Security Hub. 15/10/2025 15/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Study at the office. - Watch Module 6 - Database Concept + Amazon RDS \u0026amp; Amazon Aurora + Redshift \u0026amp; Elasticache - Double-check translated blog articles. 16/10/2025 18/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Continue reviewing Module 6 labs. - Revise Modules 1–6 to prepare for the midterm exam. 18/10/2025 19/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 6 Achievements Monday (13/10/2025):\nWatched Module 5 – Shared Responsibility Model.\nStudied Amazon Identity and Access Management (IAM) to understand user and role permissions.\nTuesday (14/10/2025):\nContinued learning about IAM.\nStudied Amazon Cognito for authentication and user identity management.\nLearned AWS Organizations to manage multiple AWS accounts efficiently.\nWednesday (15/10/2025):\nStudied AWS Identity Center for centralized access management.\nExplored Amazon Key Management Service (KMS) for key creation, encryption, and security management.\nLearned about AWS Security Hub, a tool for continuous security monitoring.\nThursday (16/10/2025):\nStudied at the office and practiced using AWS services.\nWatch Module 6.\nCarefully checked translated AWS blogs for accuracy.\nFriday (17/10/2025):\nContinued with Module 6 labs for hands-on learning.\nReviewed Modules 1–6 thoroughly to prepare for the upcoming midterm exam.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Review AWS lab modules.\nStudy materials for the midterm exam.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review Lab Module 1. - Review midterm exam topics. 20/10/2025 21/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Review Modules 1 and Lab 1. 21/10/2025 21/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Review Modules 2 and Lab 2. 22/10/2025 22/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Review Modules 3 \u0026amp; 4 and their labs. Go to the office for studying 23/10/2025 25/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Review Modules 5 \u0026amp; 6 and their labs. Go to the office for studying 24/10/2025 26/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; Week 7 Achievements Monday (20/10/2025):\nReviewed Lab Module 1 to reinforce practical AWS concepts.\nReview midterm exam content.\nTuesday (21/10/2025):\nCompleted review of Module 1 and Lab 1.\nUnderstanding of AWS basics, including global infrastructure and shared responsibility.\nWednesday (22/10/2025):\nReviewed Module 2 and Lab 2.\nPracticed hands-on exercises related to VPC, subnets, and EC2 instances.\nThursday (23/10/2025):\nGo to the office for studying.\nReviewed Modules 3 \u0026amp; 4 and its labs.\nStrengthened understanding of S3, EBS, and Disaster Recovery concepts.\nFriday (24/10/2025):\nGo to the office for studying.\nReviewed Module 5 \u0026amp; 6 and its labs.\nConsolidated knowledge across Modules 1–6 in preparation for the midterm exam.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Midterm Exam Review this week. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review theory for Module 1-2. 27/10/2025 27/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 3 - Review theory for Module 3-4. 28/10/2025 29/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 4 - Review theory for Module 5-6. 29/10/2025 29/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 5 - Review all theory from 6 modules. 30/10/2025 30/10/2025 \u0026lt;Youtube: AWS Study Group\u0026gt; 6 - Go to the office for the Midterm Exam. 31/10/2025 31/10/2025 Week 8 Achievements: Monday (27/10/2025):\nReview Module 1–2. Tuesday (28/10/2025):\nReview Module 3–4. Wednesday (29/10/2025):\nReview Module 5–6. Thursday (30/10/2025):\nSummarize and consolidate all knowledge from Module 1–6. Friday (31/10/2025):\nMidterm Exam at the Office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Review the structure of the project. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read the project documentation. 03/11/2025 03/11/2025 3 - Review the project diagram. 04/11/2025 04/11/2025 4 - Identify the services required by the project. 05/11/2025 05/11/2025 5 - Determine how many services need to be applied. 06/11/2025 06/11/2025 6 - Review the overall structure of the project. 07/11/2025 07/11/2025 Week 9 Achievements: Monday (03/11/2025):\nRead through the project documentation to understand its purpose and scope. Tuesday (04/11/2025):\nReviewed the project diagram to visualize the system architecture. Wednesday (05/11/2025):\nExamined which services are required for the project implementation. Thursday (06/11/2025):\nDetermined the total number of services needed and how they integrate with the system. Friday (07/11/2025):\nReviewed the overall structure of the project to consolidate understanding. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Typically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting familiar with AWS and its basic services.\nWeek 2: Practicing with technologies and understanding basic AWS services.\nWeek 3: Understanding how to use AWS technologies and basic services, including both the Console and CLI.\nWeek 4: Creating an AWS account and working with AWS modules.\nWeek 5: Continuing AWS learning through YouTube resources.\nWeek 6: Exploring more AWS services via YouTube.\nWeek 7: Reviewing modules and preparing for the Midterm\nWeek 8: Comprehensive review and taking the Midterm exam\nWeek 9: Exploring the project structure and related services\nWeek 10: Reviewing and analyzing the project’s workflow\nWeek 11: Implement coding project \u0026amp; participate in AWS events\nWeek 12: Coding, testing modules \u0026amp; participating in AWS events\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.2-prerequisites/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "Before starting the workshop, ensure you have access to the following:\nAccounts \u0026amp; Access An AWS Account IAM User with permissions to: Amazon VPC Amazon EC2 Elastic IP NAT Gateway Internet Gateway Recommended policy: AdministratorAccess (for lab purposes only) If you are using an IAM user, make sure you have access keys or console login credentials.\nCost Notice This workshop includes creating a NAT Gateway, which is a billable resource. To minimize cost, you should delete all created resources during the cleanup step.\nexpected workshop cost: ~ few USD if resources are cleaned up the same day\nTools Required Tool Usage AWS Management Console Main interface for building VPC, Subnets, Route Tables SSH client (PuTTY / Terminal) Used later to connect to EC2 instances Key Pair Needed for EC2 login (you will create one during the workshop) Region Selection We recommend using the region closest to you for lower latency.\nExample: ap-southeast-1 (Singapore) for Vietnam users.\nYou must keep the same region for all steps in this workshop.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "AWS Cloud Health Dashboard 1. Executive Summary AWS Cloud Health Dashboard is a production-grade, multi-tenant SaaS platform with automated DevSecOps implementation that enables businesses to monitor and optimize AWS infrastructure for multiple clients from a single centralized system.\nKey Highlights: Production-Grade Architecture: Application Load Balancer with SSL/TLS termination, Elastic IP, health checks, and zero-downtime deployment capability DevSecOps Pipeline: Automated CI/CD with security scanning and blue-green deployment strategy Multi-tenant Architecture: Designed to support 10-50+ AWS client accounts (demo tested with 3-5 clients) High Availability: ALB with health checks, automatic failover capability, and 99.99% SLA Platform cost: $39-49/month (Year 1) with production-grade infrastructure Per-client cost: ~$0.59/month (scalable and predictable) Security-first design: AWS Secrets Manager + KMS encryption + ACM certificates Automated deployment: CodePipeline + CodeBuild with zero-downtime deployment 5 DynamoDB tables: Optimized data model with client isolation Redis caching: Potential 60-80% database read cost reduction Email notification system: AWS SES integration for critical alerts Elastic IP: FREE static IP for production stability Technology Stack: FastAPI (Python) + React + DynamoDB + Redis + ALB + Elastic IP + ACM + AWS Secrets Manager + KMS + CloudWatch + CloudTrail + CodePipeline + CodeBuild + EC2 t3.micro 2. Problem Statement Current Challenges: Businesses managing AWS infrastructure for multiple clients face:\nNo centralized monitoring: Must log into each client\u0026rsquo;s AWS console separately Scattered security alerts: Critical GuardDuty findings go unnoticed Cost visibility gaps: Difficult to track and optimize costs across clients Insecure credential management: AWS access keys stored in databases or config files No automated deployment: Manual deployment leads to errors and downtime Lack of security scanning: Vulnerabilities deployed to production No audit logging: Cannot track security events and API calls Manual monitoring: 30+ minutes daily per client Downtime during deployments: No zero-downtime deployment strategy Dynamic IPs: IP changes on restart causing DNS/whitelist issues Our Solution: Cloud Health Dashboard provides a production-grade platform with DevSecOps practices including:\nProduction-Grade Infrastructure Application Load Balancer for high availability and traffic distribution Elastic IP for stable, persistent IP address (FREE when attached) SSL/TLS termination with AWS Certificate Manager (ACM) Health checks with automatic failover Zero-downtime deployment capability Horizontal scaling readiness (currently single EC2, designed for multi-instance) 99.99% ALB SLA guarantee DevSecOps Architecture Automated CI/CD pipeline (CodePipeline + CodeBuild) Security scanning (SAST with Bandit, dependency scanning with Safety) Blue-green deployment strategy for zero downtime Infrastructure monitoring with CloudWatch Audit logging with CloudTrail Secrets management with AWS Secrets Manager + KMS Multi-Tenant Architecture Scalable architecture to monitor 10-50+ AWS client accounts (MVP demo with 3-5 clients) AWS Secrets Manager for credential storage (KMS encrypted) Complete data isolation between clients Task scheduling system for data collection Centralized Monitoring Single dashboard for all clients Real-time infrastructure health Historical data retention (30-365 days) 15+ AWS services monitored Redis caching for performance optimization 3. Solution Architecture Architecture Overview Key Components: Internet Gateway: VPC entry point for incoming traffic Application Load Balancer (ALB): Distributes traffic across availability zones SSL/TLS termination with ACM certificates Health checks with automatic failover Path-based routing capability DDoS protection (AWS Shield Standard) Elastic IP: Static public IPv4 address for EC2 instance FREE when attached to running instance Persistent across instance restarts Enables stable SSH access and IP whitelisting EC2 Instance (t3.micro): Application server processing Zero-Downtime Deployment: Blue-green strategy using target groups DynamoDB: Multi-tenant data storage Redis: In-memory caching layer AWS Secrets Manager: Secure credential storage CloudWatch \u0026amp; CloudTrail: Monitoring and audit logging Data Flow 1. DEVELOPER WORKFLOW (DevSecOps with Zero-Downtime Deployment) Developer → Git push → GitHub → CodePipeline triggered\r→ CodeBuild runs:\r• Install dependencies\r• Run tests (pytest)\r• Security scan (Bandit, Safety)\r• Build frontend\r• SSH to EC2 (via Elastic IP) → Deploy new version\r• ALB health check validates deployment\r• Traffic cutover (zero downtime)\r→ CloudWatch logs everything 2. INCOMING TRAFFIC (Production Flow) Client Browser → HTTPS (Cloudflare CDN/SSL)\r→ Internet Gateway → ALB (ACM certificate, SSL termination)\r→ Target Group (health check: /health endpoint)\r→ EC2 Instance (Elastic IP attached, FastAPI application)\r→ Response back through ALB → Client 3. CLIENT SIGNUP Customer → Enter AWS Access key → Click login → Account auto create\r→ API (through ALB) → Validate AWS keys\r→ Store in Secrets Manager (KMS encrypted)\r→ Store metadata in DynamoDB 4. EMAIL VERIFICATION Customer → Enter email → Check email → Send verify email → Click link → ALB → API → Verify token\r→ Mark email verified → CloudTrail logs event 5. WORKER MANAGER (Multi-Tenant) Every 15 min → Fetch active clients from DynamoDB\r→ For each client:\r• Get credentials from Secrets Manager\r• Schedule async task for data collection\r• Collect AWS data\r• Cache in Redis (5 min TTL)\r• Store in DynamoDB 6. DATA COLLECTION (Per Client) Async Task → Secrets Manager (get credentials)\r→ Client AWS API → Collect metrics\r→ Cache in Redis → Store in DynamoDB (partitioned by aws_account_id)\r→ If critical finding → Send email alert (SES)\r→ CloudWatch logs all operations 7. DASHBOARD DISPLAY Customer login → Request through ALB → FastAPI checks Redis cache\r→ Cache HIT: Return cached data (\u0026lt; 200ms)\r→ Cache MISS: Query DynamoDB (filtered by aws_account_id)\r→ Store in Redis → Return data through ALB 8. HEALTH CHECKS \u0026amp; FAILOVER ALB → Every 30s → GET /health endpoint\r→ If unhealthy (2 consecutive failures):\r• Mark target unhealthy\r• Stop routing traffic\r• CloudWatch alarm triggered\r• Systemd attempts auto-restart\r→ When healthy: Resume traffic routing 9. SSH ACCESS \u0026amp; MANAGEMENT DevOps Engineer → SSH to Elastic IP\r→ Direct EC2 access for:\r• Deployment verification\r• Log inspection\r• Emergency troubleshooting\r• System maintenance\r→ Stable IP (no DNS updates needed) 10. SECURITY \u0026amp; AUDIT All API calls → CloudTrail logging\rCredentials access → CloudWatch alarm\rFailed auth attempts → Email alert\rKMS key usage → Audit trail\rALB access logs → S3 (optional, for compliance) 4. Key Features Production-Grade Infrastructure Application Load Balancer (ALB): High Availability: Distributes traffic across multiple availability zones SSL/TLS Termination: ACM certificates for HTTPS encryption Health Checks: Automatic failover if EC2 becomes unhealthy Path-Based Routing: Frontend and API routing (future expansion ready) DDoS Protection: AWS Shield Standard (automatic, no cost) 99.99% SLA: AWS-guaranteed uptime Zero-Downtime Deployment: Target group switching for blue-green deployments Elastic IP: Static IP Address: Persistent public IPv4 that never changes FREE Cost: $0/month when attached to running EC2 instance Stable SSH Access: Reliable management access with fixed IP IP Whitelisting: Enable third-party integrations with consistent IP No DNS Updates: IP persists across instance restarts Disaster Recovery: Quick failover while maintaining same IP SSL/TLS Security: ACM-managed certificates (automatic renewal) TLS 1.2/1.3 support End-to-end encryption (Cloudflare → ALB → EC2) Perfect Forward Secrecy (PFS) Strong cipher suites only Scalability Readiness: Horizontal scaling capable (currently single EC2) Target group architecture supports multiple instances Auto Scaling Group ready (future implementation) Connection draining for graceful shutdowns DevSecOps Implementation Automated CI/CD Pipeline: GitHub integration for source control CodePipeline for orchestration (1 pipeline FREE) CodeBuild for automated builds (100 mins/month FREE) Automated security scanning before deployment Zero-downtime deployment via ALB target groups SSH deployment to Elastic IP for reliability Health check validation before traffic cutover Security Scanning: Bandit: Static Application Security Testing (SAST) Safety: Dependency vulnerability scanning Pre-deployment security gates Build fails on HIGH severity issues Deployment Strategy: Blue-green deployment using ALB target groups Health check validation (/health endpoint) Automatic rollback on failure Connection draining during deployment Zero customer impact during updates Secrets Management: AWS Secrets Manager for credential storage KMS encryption for all secrets Rotation policy support (configurable in production) No credentials in code or environment variables IAM role-based access only Monitoring \u0026amp; Logging: CloudWatch for application logs and metrics CloudTrail for API audit logging ALB access logs (optional, for compliance) Custom metrics for business KPIs Automated alerts for anomalies 90-day log retention Infrastructure Security: Network Layer: Security Groups: HTTPS (443) from ALB only to EC2 ALB Security Group: HTTPS (443) from Internet (0.0.0.0/0) SSH access (22) to Elastic IP from management IPs only Application Layer: JWT-based authentication with IP validation Rate limiting (100 req/min per IP) CORS policy enforcement Infrastructure Layer: AWS Shield Standard (DDoS protection) SSL/TLS termination at ALB IAM roles with least privilege KMS encryption for data at rest VPC isolation Multi-Tenant Management Self-service client signup with AWS key validation Credentials stored in Secrets Manager (KMS encrypted) Task scheduling system for periodic data collection Complete data isolation Per-client dashboard access Redis caching for performance optimization Email Notification System Email verification with secure tokens (24h expiry) Critical alerts via AWS SES Customizable notification preferences HTML email templates Email management in Settings page Note: SES sandbox mode requires email verification before sending Infrastructure Monitoring Real-time metrics from 15+ AWS services Historical data retention (30+ days) Redis caching (performance optimization) EC2, S3, RDS, Lambda monitoring Service health dashboards ALB metrics (request count, latency, healthy targets) Cost Optimization Daily cost tracking per service Monthly cost trends AWS Cost Explorer recommendations Budget alerts Per-client cost analysis Security Monitoring GuardDuty integration support (demo uses simulated findings) Severity-based filtering Email alerts for critical findings CloudTrail audit logging Compliance status tracking 5. Technical Implementation Technology Stack Frontend: React 18 with Vite TanStack Query for data fetching Recharts for visualization Tailwind CSS for styling Backend: Python 3.12+ with FastAPI boto3 (AWS SDK) asyncio for concurrent task execution Redis for caching pytest for testing uvicorn ASGI server Infrastructure: Load Balancer: Application Load Balancer (ALB) Networking: Elastic IP (static public IPv4) Compute: EC2 t3.micro (1 vCPU, 1GB RAM, Ubuntu 22.04 LTS) Database: DynamoDB (5 tables, on-demand pricing) Cache: Redis (in-memory, localhost) Networking: VPC with public subnet, Internet Gateway DevSecOps: GitHub (source control) CodePipeline (CI/CD orchestration) CodeBuild (automated builds) Bandit (SAST security scanner) Safety (dependency scanner) Security: AWS Certificate Manager (ACM) - SSL/TLS certificates AWS Secrets Manager (credential storage) AWS KMS (encryption keys) CloudTrail (audit logging) CloudWatch (monitoring \u0026amp; alerts) Security Groups (network firewall) Email: AWS SES (Simple Email Service) HTML email templates Email verification with tokens Alert notifications 6. Cost Analysis Cost Note: Estimates based on AWS us-east-1 pricing (December 2025) using AWS Pricing Calculator. Assumptions: 10 clients, 15-min collection interval, 30-day data retention.\nYear 1 Costs (Maximum Free Tier) AWS Service Cost/Month Notes Application Load Balancer $16.20 $0.0225/hour + LCU charges Elastic IP $0 FREE when attached to running EC2 EC2 t3.micro (750h free) $0 (12 months) Free tier first year DynamoDB (25GB free) $0-3 Free tier + overage S3 (5GB free) $0-1 Backups + ALB logs (optional) CloudWatch (10 metrics free) $0-2 Additional metrics Secrets Manager (1 secret) $0.40 Per secret/month ACM Certificate $0 FREE for ALB/CloudFront CodePipeline (1 pipeline free) $0 First pipeline free CodeBuild (100 mins/mo free) $0 Within free tier CloudTrail (1 trail free) $0 Management events free KMS (20,000 requests free) $0-1 Mostly within free tier SES (3,000 emails free) $0 Verification + alerts Data Transfer (1GB free) $0-1 ALB to EC2 (no charge in same AZ) TOTAL Year 1 $39-49/month Production-grade infrastructure Year 2+ Costs AWS Service Cost/Month Notes Application Load Balancer $16.20 $0.0225/hour + LCU charges Elastic IP $0 FREE when attached to running EC2 EC2 t3.micro $8-10 On-demand pricing DynamoDB $3-5 Storage + operations CloudWatch $2-4 Logs + metrics Secrets Manager $0.40 Per secret/month ACM Certificate $0 FREE for ALB CodePipeline $0 First pipeline free CodeBuild $0 Within free tier limits CloudTrail $0 Management events free KMS $1-2 Key storage + requests SES $2-5 Email sending S3 $1 Backups + logs Data Transfer $1 Outbound traffic TOTAL Year 2+ $47-57/month Production-grade with ALB Scaling Costs Year 1 (Free Tier EC2): 10 clients: Platform $39 + (10 × $0.59) = $44.90/month 20 clients: Platform $39 + (20 × $0.59) = $50.80/month 50 clients: Platform $39 + (50 × $0.59) = $68.50/month Year 2+ (Paid EC2): 10 clients: Platform $47 + (10 × $0.59) = $52.90/month 20 clients: Platform $47 + (20 × $0.59) = $58.80/month 50 clients: Platform $47 + (50 × $0.59) = $76.50/month Scale Note: With EC2 t3.micro, the platform can efficiently support 10-20 clients. To scale to 50+ clients, upgrade to larger instances (t3.small/medium) is recommended. ALB architecture makes horizontal scaling straightforward by adding instances to the target group.\nFuture Optimizations: Reserved Instances: 30-40% savings on EC2 (after 12 months) Savings Plans: Flexible commitment-based discounts Spot Instances: For non-critical background tasks (70-90% savings) S3 Intelligent-Tiering: Automatic cost optimization for backups CloudWatch Logs optimization: Adjust retention (7-90 days) Total Infrastructure Investment: Year 1: $39-49/month (with free tier EC2 + Elastic IP) Year 2+: $47-57/month (full pricing, Elastic IP still FREE) Per Client: $0.59/month (scalable and predictable) This represents exceptional value for a production-grade, highly available, secure multi-tenant SaaS platform with static IP infrastructure.\n7. Risk Assessment Risk Impact Probability Mitigation Budget overrun Medium Low AWS Budget alerts, Redis caching, DynamoDB on-demand, ALB cost monitoring, Elastic IP kept attached (FREE) ALB costs exceed estimates Medium Low Monitor LCU usage, optimize for single AZ (dev), CloudWatch cost alarms Elastic IP charges Low Very Low Keep EC2 running 24/7, monitor attachment status, CloudWatch alarm if detached EC2 downtime High Very Low ALB health checks, systemd auto-restart, automatic failover, Elastic IP enables quick recovery, target 99.5% uptime ALB misconfiguration High Low Health check validation, target group testing, CodeBuild deployment validation SSL certificate expiry Medium Very Low ACM auto-renewal (60 days before expiry), CloudWatch alarms IP address changes Low Very Low Elastic IP prevents IP changes, persistent across restarts SSH access loss Medium Very Low Elastic IP provides stable SSH endpoint, backup access via ALB Client data security High Low Secrets Manager + KMS, IAM least privilege, audit logging, ALB access logs CI/CD pipeline failure Medium Low CodeBuild retry logic, deployment rollback, health check gates, SSH via Elastic IP for manual fixes Redis cache failure Medium Low Systemd monitor, auto-restart, graceful degradation to DynamoDB DynamoDB hot partitions Medium Low Proper partition key design, aws_account_id sharding Secrets Manager costs Medium Medium Monitor usage, evaluate shared secret patterns in future Email delivery issues Medium Low AWS SES monitoring, retry logic, fallback notifications Security vulnerability in deps High Medium Safety scanner in CI/CD, automated updates, security alerts Scope creep Medium High Strict MVP definition, feature freeze week 8, Phase 2 plan Health check false positives Low Low Tune health check thresholds (2 failures before unhealthy) 8. Expected Outcomes Technical Deliverables Production-Grade Infrastructure: Application Load Balancer with SSL/TLS termination Elastic IP for stable SSH access and IP whitelisting (FREE) ACM-managed certificates with automatic renewal Health checks with automatic failover capability Zero-downtime deployment using target groups Horizontal scaling readiness (multi-instance capable) 99.99% ALB uptime SLA DevSecOps Platform: Automated CI/CD pipeline (GitHub → CodePipeline → CodeBuild → EC2 via Elastic IP) Automated security scanning (Bandit SAST, Safety dependency scan) Blue-green deployment strategy through ALB CloudWatch monitoring and CloudTrail audit logging AWS Secrets Manager for credential storage KMS encryption for all sensitive data Redis caching layer on EC2 Multi-Tenant SaaS: Client signup with email verification 5 DynamoDB tables with proper data isolation Task scheduling system for data collection (demo with 3-5 clients) Real-time monitoring dashboard per client Email notification system Settings page with email/notification management Performance Targets: API response time: Target \u0026lt;200ms (Redis cache HIT), \u0026lt;2s (cache MISS) ALB response time: Additional \u0026lt;50ms latency (SSL termination + routing) SSH access: Direct access via Elastic IP for deployment and troubleshooting Email delivery: \u0026lt;30 seconds (SES sandbox mode, requires email verification) Data collection: Every 15 minutes per client Platform uptime: Target 99.5%+ (ALB 99.99% SLA + EC2 with health checks) Health check interval: 30 seconds (2 consecutive failures = unhealthy) Deployment time: \u0026lt;5 minutes (zero downtime with blue-green) Build time: Target \u0026lt;5 minutes (within free tier limits) Security \u0026amp; Compliance: Zero credentials in code or environment variables All secrets encrypted with KMS SSL/TLS end-to-end encryption (Cloudflare → ALB → EC2) Stable Elastic IP for SSH access (no dynamic IP changes) Email verification before critical alerts Complete API audit trail (CloudTrail) ALB access logs available (optional, for compliance) Data isolation between clients IAM least privilege roles Automated security scanning in CI/CD Learning Outcomes Production Infrastructure Mastery: Application Load Balancer configuration and management Elastic IP allocation and management (cost optimization) SSL/TLS certificate management with ACM Health checks and target group configuration Zero-downtime deployment strategies High availability architecture patterns Network security with Security Groups Static IP management for production stability DevSecOps Mastery: CI/CD pipeline design and implementation Automated security scanning (SAST, dependency scanning) Blue-green deployment implementation Secrets management best practices Audit logging and compliance Monitoring and alerting Automated deployment strategies SSH-based deployment via stable IP AWS Services Mastery: Advanced DynamoDB (multi-tenant, GSI, TTL) Application Load Balancer (ALB) configuration Elastic IP allocation and best practices AWS Certificate Manager (ACM) integration AWS Secrets Manager + KMS integration CloudWatch + CloudTrail CodePipeline + CodeBuild AWS SES integration IAM roles and policies VPC networking and Security Groups SaaS Architecture: Multi-tenant data modeling Background task orchestration Secure credential management Caching strategies (Redis) Email notification system Scalable infrastructure design Static IP infrastructure patterns Full-Stack Development: FastAPI async programming React state management Redis integration Security-first development RESTful API design Health check endpoint implementation Portfolio Value This project demonstrates:\nProduction-Grade Infrastructure Application Load Balancer for high availability Elastic IP for stable infrastructure (FREE optimization) SSL/TLS termination with ACM certificates Zero-downtime deployment capability Health checks with automatic failover Horizontal scaling readiness DevSecOps Implementation Automated CI/CD pipeline with security scanning Blue-green deployment strategy Secrets management with AWS Secrets Manager + KMS Comprehensive monitoring and logging Automated deployment with health validation SSH deployment via static Elastic IP Enterprise Architecture Scalable multi-tenant SaaS design Infrastructure scalable (MVP tested with 3-5, designed for 10-50+ clients) Redis caching layer Background task scheduling system Production-ready security patterns Cost-optimized infrastructure (Elastic IP FREE) Security Expertise Zero secrets in code End-to-end encryption (Cloudflare → ALB → EC2) KMS encryption CloudTrail audit logging Automated vulnerability scanning Multi-layer security (network + application + infrastructure) Stable IP for secure SSH access AWS Proficiency 17+ AWS services integrated (added ALB + Elastic IP + ACM) Cost-optimized design (Elastic IP FREE when attached) Free tier maximization IAM best practices High availability architecture Static IP management Cost Efficiency $39-49/month for platform (Year 1) $0.59/client/month incremental Redis caching for read cost optimization Elastic IP FREE (saves $3.65/month per IP) Justifiable ALB cost for production-grade features Key Differentiators: Production-grade infrastructure with ALB, Elastic IP, and ACM (not just basic EC2) Zero-downtime deployment capability (blue-green strategy) 99.99% uptime SLA through ALB Stable IP infrastructure with FREE Elastic IP Cost optimization (Elastic IP attached = $0) Automated DevSecOps pipeline with security gates Production-grade security (Secrets Manager + KMS + ACM) Automated CI/CD with automated testing Multi-tenant architecture with data isolation Comprehensive monitoring and audit logging Horizontal scaling readiness (demonstrates understanding of growth) 9. Conclusion AWS Cloud Health Dashboard is a production-grade, multi-tenant SaaS platform with automated DevSecOps practices that demonstrates:\nProduction Infrastructure Application Load Balancer for high availability and traffic management Elastic IP for stable, persistent IP address (FREE when attached) SSL/TLS termination with AWS Certificate Manager Health checks with automatic failover Zero-downtime deployment capability Horizontal scaling readiness 99.99% ALB uptime SLA DevSecOps Implementation Automated CI/CD pipeline (CodePipeline + CodeBuild) Security scanning before every deployment Blue-green deployment strategy SSH deployment via stable Elastic IP Secrets management with AWS Secrets Manager + KMS Comprehensive monitoring (CloudWatch + CloudTrail) Enterprise Architecture Scalable multi-tenant design (MVP tested with 3-5, designed for 10-50+ clients) Scalable task scheduling system Redis caching for performance Complete data isolation Production-ready infrastructure patterns Cost-optimized design (Elastic IP FREE) Security-First Design Zero secrets in code or config files End-to-end encryption (Cloudflare → ALB → EC2) KMS encryption for all sensitive data CloudTrail audit logging Automated vulnerability scanning Multi-layer security architecture Stable SSH access via Elastic IP AWS Expertise Deep integration with 17+ AWS services Cost-optimized infrastructure ($39-49/month Year 1) Elastic IP cost optimization (FREE vs $3.65/month) Security best practices Email notification system (SES) High availability architecture Business Acumen Cost-efficient operation with production-grade features Scalable pricing model ($0.59/client/month) Professional SaaS features Clear ROI for clients Justifiable infrastructure investment Investment Justification: The ~$16/month for ALB + $0/month for Elastic IP (FREE) is strategically justified:\nTransforms project from demo to production-grade portfolio piece Demonstrates enterprise architecture patterns Enables zero-downtime deployments Provides 99.99% uptime SLA Shows scalability readiness (critical for DevOps/SRE roles) Proves understanding of high availability and failover strategies Elastic IP adds production stability at zero cost Shows cost optimization skills (keeping Elastic IP attached = FREE) Timeline: 3 months | Team: 4 people | Budget: $39-49/month (Year 1), $47-57/month (Year 2+)\nThis project demonstrates production-grade infrastructure and DevSecOps practices implementation, making it a compelling portfolio piece for cloud engineering, DevOps, and SRE roles.\nAppendices A. Services Used (17 AWS Services - Production Grade): Application Load Balancer (ALB) - Traffic distribution \u0026amp; high availability Elastic IP - Static public IPv4 address (FREE when attached to running EC2) AWS Certificate Manager (ACM) - SSL/TLS certificate management (FREE for ALB) EC2 (Compute) DynamoDB (Database) AWS Secrets Manager (Credential storage) AWS KMS (Encryption) CloudWatch (Monitoring) CloudTrail (Audit logging) CodePipeline (CI/CD) CodeBuild (Automated builds) SES (Email) S3 (Backup \u0026amp; ALB logs) VPC (Networking) Internet Gateway (Connectivity) Security Groups (Firewall) IAM (Access management) Shield Standard (DDoS protection - automatic) B. Architecture Improvements from ALB + Elastic IP: High Availability: 99.99% uptime SLA Zero-Downtime Deployment: Blue-green strategy with target groups SSL/TLS Termination: Offload encryption from EC2 Health Checks: Automatic failover capability Horizontal Scaling: Ready to add multiple EC2 instances DDoS Protection: AWS Shield Standard integration Stable IP Infrastructure: Elastic IP (FREE when attached) SSH Management: Reliable access via fixed Elastic IP IP Whitelisting: Enable third-party integrations Cost Optimization: Elastic IP FREE (saves $3.65/month) Production-Grade: Enterprise-ready infrastructure pattern C. Cost Optimization Wins: Elastic IP: $0/month (FREE when attached) vs $3.65/month (idle) ACM Certificate: $0/month (FREE for ALB) vs $0.75/month (public certificate) Redis Caching: 60-80% reduction in DynamoDB read costs Free Tier: EC2, CodePipeline, CodeBuild, S3, CloudWatch (Year 1) Efficient Architecture: Single ALB + Elastic IP serves all clients D. GitHub Repository https://github.com/Unvianpetronas/Cloud_health_dashboard\nE. Domain cloudhealthdashboard.xyz (Cloudflare DNS + CDN)\nF. Contact Information Project Lead: Truong Quoc Tuan Email: unviantruong26@gmail.com WhatsApp: +84 798806545 "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Review the structure and services in the project.\nUnderstand the flow of activities and the connection between system components.\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study at the office. - Review the project structure. 10/11/2025 10/11/2025 3 - Examine the details of the services used in the project. 11/11/2025 11/11/2025 4 - Analyze the overall system workflow. 12/11/2025 12/11/2025 5 - Check the relationships and dependencies between services. 13/11/2025 13/11/2025 6 - Summarize the week’s findings and note unclear points. 14/11/2025 14/11/2025 7 - Attending the AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS event at the office. 14/11/2025 14/11/2025 Week 10 Achievements: Monday (10/11/2025):\nStudied at the office as planned.\nReviewed the overall project structure and understood the main components and folder organization.\nTuesday (11/11/2025):\nExamined the specific services implemented in the project.\nTook notes on the function and purpose of each service for future reference.\nWednesday (12/11/2025):\nAnalyzed the overall system workflow.\nUnderstood how modules interact and how data flows throughout the system.\nThursday (13/11/2025):\nChecked the relationships between services.\nIdentified dependencies and potential areas for optimization.\nFriday (14/11/2025):\nSummarized all progress made during the week.\nNoted unclear areas to clarify in the upcoming week.\nSaturday (15/11/2025):\nAttending the AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS event at the office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Execute the coding project.\nAttend AWS Events at the office.\nTasks to be carried out this week: Day Task Start Date Completion Date Resources Mon - Attend the AWS Cloud Mastery Series #2: DevOps on AWS event at the office. 17/11/2025 17/11/2025 Tue - Review the modules assigned for coding in detail. 18/11/2025 18/11/2025 Wed - Begin coding the initial parts. 19/11/2025 19/11/2025 Thu - Attend the AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer event at the office. 20/11/2025 20/11/2025 Fri - Continue coding. 21/11/2025 21/11/2025 Week 11 Achievements: Monday (17/11/2025):\nAttended the AWS Cloud Mastery Series #2: DevOps on AWS event at the office. Tuesday (18/11/2025):\nThoroughly reviewed the modules assigned by the leader for coding. Wednesday (19/11/2025):\nStarted coding the initial parts of the project. Thursday (20/11/2025):\nAttended the AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer event at the office. Friday (21/11/2025):\nContinued coding the assigned modules. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Code the assigned modules.\nLeader assigned the tasks: System Foundation \u0026amp; Testing.\nTasks to be Implemented This Week: Day Task Start Date Completion Date Resources Mon - Code the first assigned modules. 24/08/2025 25/08/2025 Tue - Continue coding. 25/08/2025 26/08/2025 Wed - Hand over the rough code to the leader for review and adjustments. 26/08/2025 27/08/2025 Thu - Begin Testing the completed modules. 27/08/2025 28/08/2025 Fri - Continue Testing. 28/08/2025 29/08/2025 Sat - Attend the AWS Cloud Mastery Series #3 event at the office: Following the AWS Well-Architected Security Pillar. 29/08/2025 29/08/2025 Week 12 Achieved Outcomes: Monday (24/11/2025):\nCoded the assigned modules. Tuesday (25/11/2025):\nContinued coding the assigned modules. Wednesday (26/11/2025):\nHanded over the rough code to the leader for review, correction, and supplementation within the code. Thursday (27/11/2025):\nPerformed Testing on the completed modules. Friday (28/11/2025):\nContinued Testing the modules. Saturday (29/11/2025):\nAttended the AWS Cloud Mastery Series #3: Following the AWS Well-Architected Security Pillar event at the office. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/3-translatedblog/",
	"title": "Blog Translated",
	"tags": [],
	"description": "",
	"content": "This section will list and introduce the blogs that I have translated.\nBlog 1 - AWS DMS validation: A custom serverless architecture. This blog presents how AWS designed a custom serverless architecture to automate and optimize the data validation process in AWS Database Migration Service (DMS). It provides a step-by-step guide on building a post-migration data verification system using AWS Lambda, Step Functions, S3, and DynamoDB — ensuring data integrity and accuracy between source and target. Additionally, the blog shares a reference architecture, implementation details of the validation workflow, and cost optimization tips for operating the system. Read full blogs on Google Docs\nBlog 2 - Transforming network operations with AI: How Swisscom built a network assistant using Amazon Bedrock. This blog describes how Swisscom — a major telecommunications provider in Europe — leveraged Amazon Bedrock to build an AI Network Assistant that supports network operations. The article explains how the system utilizes large language models (LLMs) to automatically analyze logs, diagnose issues, and suggest solutions for network engineers. In addition, it introduces the overall AI architecture, the model training and integration process, and the performance and accuracy improvements Swisscom achieved through Generative AI. Read full blogs on Google Docs\nBlog 3 - Introducing the latest AWS Well-Architected Framework: IoT Lens. This blog introduces the AWS Well-Architected IoT Lens, a new extension of the AWS Well-Architected Framework designed to help businesses architect and evaluate their IoT systems following AWS best practices. The article outlines the five core pillars — operational excellence, security, reliability, performance efficiency, and cost optimization — in the context of IoT, along with reference architectures, best practices, and automated assessment tools. It serves as a valuable resource for engineers aiming to ensure their IoT systems are secure, efficient, and scalable on the AWS platform. Read full blogs on Google Docs\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.3-vpc-subnets/",
	"title": "Create VPC &amp; Subnets",
	"tags": [],
	"description": "",
	"content": "#In this component, you will create your own Virtual Private Cloud (VPC) and define two subnets:\n1 Public Subnet (Internet accessible) 1 Private Subnet (no direct Internet access) 3.1 Create the VPC Open AWS Management Console Navigate to Services → VPC Click Create VPC Select VPC Only Enter the details: Name tag: Workshop-VPC IPv4 CIDR: 10.0.0.0/16 Keep all other settings at default Click Create VPC 3.2 Create Public Subnet In the left menu, click Subnets Click Create subnet Configure as follows: VPC: Workshop-VPC Subnet name: Public-Subnet Availability Zone: (any, example: ap-southeast-1a) IPv4 CIDR block: 10.0.1.0/24 Click Create subnet 3.3 Create Private Subnet Click Create subnet again Fill in the values: VPC: Workshop-VPC Subnet name: Private-Subnet Availability Zone: (can be same or different) IPv4 CIDR block: 10.0.2.0/24 Click Create subnet This process is similar to 3.2 with only minor differences. Please see 3.2 section for reference.\n3.4 Enable Auto-Assign Public IP (Only for Public Subnet) Go to Subnets Select Public-Subnet Click Actions → Edit subnet settings Enable: ☑ Auto-assign public IPv4 Click Save Expected result: You now have a VPC with two subnets ready to use.\nComponents created so far:\nResource Name CIDR VPC Workshop-VPC 10.0.0.0/16 Subnet 1 (Public) Public-Subnet 10.0.1.0/24 Subnet 2 (Private) Private-Subnet 10.0.2.0/24 "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.4-ig/",
	"title": "Create Internet Gateway",
	"tags": [],
	"description": "",
	"content": "The Internet Gateway (IGW) allows resources inside your Public Subnet to send and receive traffic from the Internet. Without it, even a subnet with public IP will still be isolated.\n4.1 Create an Internet Gateway In the AWS Console, open VPC service On the left panel, select Internet Gateways Click Create internet gateway Fill in: Name tag: Workshop-IGW Click Create internet gateway 4.2 Attach Internet Gateway to VPC After IGW is created, click Actions → Attach to VPC Choose Workshop-VPC Click Attach internet gateway Result Check You should now see:\nResource Status Workshop-IGW Attached to Workshop-VPC "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Reflection Report: “AWS Cloud Day Vietnam 2025 \u0026amp; GenAI Track” Event: AWS Vietnam Cloud Day.\nDate: Thursday, September 18, 2025.\nTime: 9:00 AM – 17:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nPurpose of the Event. Introduce the latest technology trends from AWS, especially Generative AI.\nShare case studies from major enterprises in Vietnam and across the region.\nDiscuss leadership strategies and organizational management in the AI era.\nExplore best practices for security and real-world applications of AI Agents.\nSpeaker List. Morning: Hon. Government Speaker – Opening remarks.\nEric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS.\nDr. Jens Lottner – CEO, Techcombank.\nMs. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network.\nJaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS.\nJeff Johnson – Managing Director, ASEAN, AWS (Moderator).\nPanelists:\nVu Van – Co-founder \u0026amp; CEO, ELSA Corp\nNguyen Hoa Binh – Chairman, Nexttech Group\nDieter Botha – CEO, TymeX\nAfternoon: Kien Nguyen – Solutions Architect, AWS.\nMichael Armentano – Principal WW GTM Specialist, AWS.\nJun Kai Loke – AI/ML Specialist SA, AWS.\nTamelly Lim – Storage Specialist SA, AWS.\nBinh Tran – Senior Solutions Architect, AWS.\nTaiki Dang – Solutions Architect, AWS.\nKey Contents. Part 1: Main Sessions (AWS Cloud Day Vietnam). Opening \u0026amp; Keynote (Eric Yeo, AWS): Overview of AWS’s vision in Vietnam and Southeast Asia.\nCustomer Keynote 1 (Techcombank): Applying AI in finance to enhance operational efficiency and customer experience.\nCustomer Keynote 2 (U2U Network): Combining blockchain and AI to build a decentralized ecosystem.\nAWS Keynote (Jaime Valles): Regional tech trends and AWS’s strategies to empower innovation.\nPanel Discussion (Jeff Johnson + CEOs):\nLeadership must drive a culture of innovation.\nGenAI as a strategic enabler, not just a tool.\nChange management is critical when integrating AI.\nPart 2: GenAI Track. Building a Unified Data Foundation on AWS for AI and Analytics Workloads (Kien Nguyen):\nStrategies to build scalable and unified data foundations for AI \u0026amp; analytics.\nUtilizing AWS services for ingestion, storage, processing, and governance.\nBuilding the Future: GenAI Adoption and Roadmap on AWS (Jun Kai Loke \u0026amp; Tamelly Lim):\nOverview of the vision, trends, and development roadmap of GenAI on AWS.\nIntroduction to AWS services and initiatives supporting enterprise adoption.\nAI-Driven Development Lifecycle (AI-DLC) Shaping the Future of Software Implementation (Binh Tran):\nIntegrating AI into the entire software development lifecycle.\nCombining AI-assisted execution with human oversight to improve speed and quality.\nSecuring Generative AI Applications (Taiki Dang):\nAddressing GenAI security challenges: infrastructure, models, applications.\nSolutions: encryption, zero-trust architecture, continuous monitoring, fine-grained access control.\nBeyond Automation: AI Agents (Michael Armentano):\nAI Agents as “intelligent partners” beyond simple automation.\nCapable of learning, adapting, and executing complex tasks → driving exponential productivity.\nKeynotes. Eric Yeo (AWS): Vision for GenAI and its applications in Southeast Asia.\nTechcombank (Dr. Jens Lottner): Real-world AI adoption in financial services.\nU2U Network (Trang Phung): Synergy between blockchain and AI to build next-gen ecosystems.\nAWS (Jaime Valles): Regional innovation trends and enterprise transformation strategies.\nPanel Discussion: Navigating the GenAI Revolution. The leadership role in aligning organizations with GenAI.\nNurturing a culture of innovation and driving AI initiatives.\nManaging organizational change during AI integration.\nTechnical Insights \u0026amp; Best Practices. Securing Generative AI Applications (Taiki Dang):\nSecurity challenges in GenAI stacks (infrastructure, model, application).\nKey practices: encryption, zero-trust, continuous monitoring, fine-grained access.\nBeyond Automation: AI Agents (Michael Armentano):\nAI Agents as intelligent collaborators beyond traditional automation.\nSelf-learning and adaptive capabilities → significant productivity gains.\nKey Takeaways. Strategic Thinking. GenAI is not just a technology—it’s a catalyst for organizational transformation.\nLeadership must foster innovation and manage change effectively\nThe convergence of AI + Blockchain + Cloud opens new opportunities.\nTechnical \u0026amp; Security Knowledge. Security is fundamental for all GenAI applications.\nZero-trust architecture and continuous monitoring ensure integrity.\nUnderstanding security from infrastructure → model → application level is critical.\nLeveraging AI Agents. AI Agents surpass traditional automation through learning and decision-making.\nIntegration can significantly boost productivity and efficiency.\nApplications to Work. Propose internal workshops on AI Strategy \u0026amp; Change Management.\nPilot AI Agents in repetitive workflows to increase efficiency.\nReview AI workload security following zero-trust and encryption principles.\nIntegrate AI-driven insights into business data analytics.\nEvent Experience. Learning from Business Leaders. Case studies from Techcombank, U2U, ELSA, and Nexttech showcased multi-industry AI adoption.\nInsights into how CEOs handle organizational change and innovation.\nHands-on Technical Insights. Gained understanding of security architecture in GenAI deployments.\nRealized the transformative potential of AI Agents in next-level automation.\nNetworking \u0026amp; Collaboration. Engaged with AWS experts and industry executives.\nRecognized the importance of collaboration between business and technology in the GenAI era.\nLessons Learned. Leadership plays a key role in enabling GenAI adoption.\nBalancing security, operational efficiency, and innovation is crucial.\nAI Agents will become an inevitable part of future workflows.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: AI/ML/GenAI on AWS Event: AWS Cloud Mastery Series #1 : AI/ML/GenAI on AWS\nDate: Saturday, November 15, 2025.\nTime: 8:30 AM – 11:30 AM.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide foundational to advanced knowledge on AI/ML and Generative AI (GenAI) services on the Amazon Web Services (AWS) platform.\n1. Welcome \u0026amp; Context (8:00 – 8:30 AM) The event kicked off with participant registration and networking among professionals and attendees.\nAn overview of learning objectives was provided, directing the content to focus on practical AWS tools.\nAn introduction to the AI/ML landscape in Vietnam highlighted key trends and major challenges in the region.\n2. AWS AI/ML Platform Overview (8:30 – 10:00 AM) This segment focused on Amazon SageMaker, the end-to-end Machine Learning (ML) platform from AWS:\nML Lifecycle: Attendees learned about the crucial stages, from data preparation and labeling to efficient model training, tuning, and deployment.\nIntegrated MLOps: Introduction to the built-in MLOps capabilities in SageMaker, which help automate and manage the model lifecycle in production environments.\nLive Demo: SageMaker Studio: A live demonstration of SageMaker\u0026rsquo;s integrated development environment (IDE), illustrating how data scientists can work effectively on the platform.\n10:00 – 10:15 AM | Coffee Break (15 minutes) 3. Generative AI (GenAI) with Amazon Bedrock (10:15 AM – 11:30 AM) After the coffee break, the focus shifted to GenAI via Amazon Bedrock, the hub for Foundation Models (FMs):\nFoundation Models: Analysis and comparison of leading FMs like Claude, Llama, and Titan, along with guidance on selecting the appropriate model for specific tasks.\nPrompt Engineering: Learning essential and advanced techniques, including Chain-of-Thought reasoning and Few-shot learning to optimize FM output.\nRetrieval-Augmented Generation (RAG): Introduction to the RAG architecture and the role of integrating a Knowledge Base to feed the FM proprietary information, enhancing accuracy.\nBedrock Agents \u0026amp; Guardrails: Exploration of how Bedrock Agents enable the creation of automated multi-step workflows. Concurrently, learning about Guardrails to ensure safety and content filtering against harmful outputs.\nLive Demo: A practical demonstration of building a simple GenAI chatbot using Bedrock components.\n11:30 AM | Finish \u0026amp; Lunch Lunch Break (Self-arranged) Event Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: FOCUS ON AWS BEDROCK AGENT AND AGENTIC WORKFLOW Event: Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock.\nDate: Friday, December 5, 2025.\nTime: 8:30 AM – 12:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide in-depth knowledge on building and operating automated workflows (Agentic Workflows) using AWS Bedrock Agent and to introduce optimization solutions from the partner, CloudThinker.\nPROGRAM SUMMARY Time Topic Speaker Key Highlights 9:00 - 9:10 Opening Nguyen Gia Hung, Head of Solutions Architect Set the goals and context for the event. 9:10 - 9:40 AWS Bedrock Agent Core Kien Nguyen, Solutions Architect Analysis of the architecture, core features, and operational mechanism of Bedrock Agent. 9:40 - 10:00 [Use Case] Building Agentic Workflow on AWS Viet Pham, Founder cum CEO Presented a real-world example of deploying automated workflows on AWS. 10:00 - 10:10 CloudThinker Introduction Thang Ton, Co-founder \u0026amp; COO Introduced the company and its solution focused on GenAI optimization. 10:10 - 10:40 CloudThinker Agentic Orchestration, Context Optimization on Amazon Bedrock (L300) Henry Bui, Head of Engineering Deep dive into Agent coordination techniques and context optimization for Bedrock. 10:40 - 11:00 Tea Break \u0026amp; Networking Opportunity for discussion and relaxation. 11:00 - 12:00 CloudThinker Hack: Hands-on Workshop Kha Van Direct practical session on building an Agentic solution. 12:00 Networking \u0026amp; Lunch Buffet IN-DEPTH KNOWLEDGE GAINED 1. Core Architecture of AWS Bedrock Agent The presentation by Mr. Kien Nguyen clarified the role of Bedrock Agent as a powerful tool to automate complex tasks by connecting Foundation Models (FM) with business systems and APIs.\nOperational Mechanism: The Agent uses the FM\u0026rsquo;s reasoning capability to analyze the user\u0026rsquo;s request, determine the necessary steps, and call Tools (Action Groups) to complete the task.\nKey Benefit: Reduces the programming effort for multi-step workflows and ensures safety (safety guardrails) when accessing internal data or systems.\n2. Practical Application: Building Agentic Workflows The Use Case from Mr. Viet Pham illustrated how to transform manual, sequential processes into automated, Agent-driven workflows.\nThe crucial point is the clear definition of system capabilities and APIs so the Agent can accurately understand and utilize them.\n3. Optimizing Agentic Workflows with CloudThinker CloudThinker\u0026rsquo;s session focused on addressing advanced (L300) challenges when operating Agents:\nAgentic Orchestration: Coordination strategies to manage multiple Agents or complex steps, ensuring consistency and performance.\nContext Optimization: Techniques for optimizing the context passed to the FM (e.g., RAG optimization, context window management) to reduce token costs and improve the Agent\u0026rsquo;s accuracy/reasoning capability.\nThis is key to deploying cost-effective and reliable Agentic applications in an enterprise environment.\n4. In-Depth Hands-on Workshop The CloudThinker Hack session, led by Kha Van, provided a valuable opportunity for attendees to:\nDirectly configure and deploy a simple Agent on Amazon Bedrock.\nApply optimization techniques for context and orchestration from CloudThinker to the built workflow.\nThe practical session reinforced theoretical knowledge and provided a better understanding of the technical challenges when moving Agents to production.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: DEVOPS ON AWS Event Name: AWS Cloud Mastery Series #2 : DevOps on AWS.\nDate: Monday, November 17, 2025.\nTime: 8:30 AM – 5:00 PM.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide comprehensive knowledge on DevOps Culture, principles, performance metrics, and the suite of AWS DevOps services for building CI/CD pipelines, IaC, and Observability.\nMORNING SESSION (8:30 AM – 12:00 PM): CI/CD \u0026amp; INFRASTRUCTURE AS CODE 1. Welcome \u0026amp; DevOps Mindset (8:30 – 9:00 AM) The event began with a quick recap from the previous AI/ML session, setting the context for moving models/applications into production. The focus was on DevOps culture and principles, emphasizing collaboration between Development (Dev) and Operations (Ops). Introduction to key performance metrics such as DORA (Deployment Frequency, Lead Time for Changes, MTTR, Change Failure Rate) and MTTR (Mean Time To Recovery). 2. AWS DevOps Services – Building the CI/CD Pipeline (9:00 – 10:30 AM) This section delved into the AWS CodeFamily suite of tools to automate Continuous Integration (CI) and Continuous Deployment (CD):\nSource Control: Using AWS CodeCommit and discussing source code management strategies like GitFlow and Trunk-based. Build \u0026amp; Test: Configuring CodeBuild to automate compilation and running testing pipelines. Deployment: Analyzing advanced deployment strategies with CodeDeploy, including Blue/Green, Canary, and Rolling updates. Orchestration: Utilizing CodePipeline to automate the entire process from commit to production. Demo: A visual demonstration of a complete CI/CD pipeline on AWS. 3. Infrastructure as Code (IaC) (10:45 AM – 12:00 PM) IaC is the foundation of modern DevOps, ensuring environment consistency and reproducibility:\nAWS CloudFormation: Learning about Templates, Stacks, and how to use Drift Detection to identify discrepancies between the actual state and the source code. AWS CDK (Cloud Development Kit): Introducing CDK as a more modern approach, using familiar programming languages (TypeScript, Python,\u0026hellip;) to define infrastructure via Constructs and reusable patterns. Demo \u0026amp; Discussion: Demonstrating infrastructure deployment using both CloudFormation and CDK, along with a discussion on criteria for choosing the right IaC tool. AFTERNOON SESSION (1:00 PM – 5:00 PM): CONTAINER, OBSERVABILITY \u0026amp; BEST PRACTICES 4. Container Services on AWS (1:00 – 2:30 PM) Docker Fundamentals: Review of basic concepts related to Microservices and Containerization. Amazon ECR (Elastic Container Registry): The service for storing container images, including image scanning features and lifecycle policies. Amazon ECS \u0026amp; EKS: Comparing the two main container orchestration services: ECS (simpler, AWS integrated) and EKS (Kubernetes-based). Analysis of deployment and scaling strategies. AWS App Runner: A simplified solution for container deployment, focusing on code over infrastructure. Demo \u0026amp; Case Study: Illustrating microservices architecture deployment and comparing the services. 5. Monitoring \u0026amp; Observability (2:45 – 4:00 PM) CloudWatch: The core tool for collecting metrics, logs, alarms, and dashboards across the entire AWS ecosystem. AWS X-Ray: Provides Distributed Tracing to track request flow across microservices, helping to identify bottlenecks and performance issues. Demo: Setting up a comprehensive observability system (Full-stack observability). Best Practices: Best practices for Alerting, dashboards, and the on-call process. 6. DevOps Best Practices \u0026amp; Case Studies (4:00 – 4:45 PM) Advanced Deployment Strategies: Discussion on Feature flags and A/B testing within the deployment pipeline. Automated testing and deep integration with CI/CD. Incident Management: Managing incidents and the importance of Postmortems for learning and improvement. Case Studies: Lessons learned from startups and large enterprises that have undergone successful DevOps transformations. 7. Q\u0026amp;A \u0026amp; Wrap-up (4:45 – 5:00 PM) Addressing in-depth questions. Providing information on DevOps career pathways and relevant AWS certifications. Event Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: THE AWS WELL-ARCHITECTED SECURITY PILLAR Event: AWS Cloud Mastery Series #3: Following the AWS Well-Architected Security Pillar.\nDate: Saturday, November 29, 2025.\nTime: 8:30 AM – 12:00 PM (GMT+7).\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To provide in-depth knowledge on the 5 pillars of the Security Pillar within the Well-Architected Framework, including core principles, services, and defense strategies.\nPROGRAM SUMMARY Time Topic Key Focus 8:30 – 8:50 Opening \u0026amp; Security Foundation Role of the Security Pillar, Shared Responsibility Model, and top cloud threats in Vietnam. 8:50 – 9:30 Pillar 1: Identity \u0026amp; Access Management (IAM) Modern IAM Architecture (Users, Roles, Policies), IAM Identity Center, SCP, MFA, and Access Analyzer Demo. 9:30 – 9:55 Pillar 2: Detection Continuous monitoring with CloudTrail, GuardDuty, Security Hub, and the Detection-as-Code model. 10:10 – 10:40 Pillar 3: Infrastructure Protection Network security (VPC segmentation, SG vs NACL), WAF, Network Firewall, and Workload security. 10:40 – 11:10 Pillar 4: Data Protection Encryption (at-rest \u0026amp; in-transit), Key Management (KMS), Secrets Management (Secrets Manager), and Data Classification. 11:10 – 11:40 Pillar 5: Incident Response AWS IR lifecycle, Playbooks (Key Compromise, S3 Exposure), and automated response (Auto-response). 11:40 – 12:00 Wrap-Up \u0026amp; Q\u0026amp;A Common pitfalls and the Security Specialty learning roadmap. IN-DEPTH KNOWLEDGE BY THE 5 PILLARS 1. Security Foundation \u0026amp; Core Principles Core Principles: Emphasis on the necessity of Least Privilege, Zero Trust (never trust, always verify), and Defense in Depth (layered defense).\nShared Responsibility Model: Clarifying the boundary of responsibility: AWS is responsible for the security of the Cloud (infrastructure, physical), while the Customer is responsible for security in the Cloud (data, IAM, configuration).\n2. Pillar 1: Identity \u0026amp; Access Management (IAM) Modern Architecture: Avoid using long-term credentials (long-lived Access Keys) for users. Prioritize Roles for services and IAM Identity Center (SSO) for users.\nMulti-Account Control: Apply Service Control Policies (SCPs) at the AWS Organizations level and Permission Boundaries to set maximum limits for delegated permissions.\nMini Demo: Demonstration of using Access Analyzer and the policy simulator tool to verify and validate access rights before deployment.\n3. Pillar 2: Detection Continuous Monitoring: Utilize CloudTrail (at the Organization level) to log all API actions, GuardDuty for ML-powered abnormal threat detection, and Security Hub to aggregate findings.\nDetection-as-Code: Defining detection rules as code (e.g., Lambda, CloudFormation) to automate deployment and management.\n4. Pillar 3: Infrastructure Protection Network Segmentation: Separate application tiers (Web, App, DB) using VPC segmentation. Clearly distinguish the roles of Security Groups (stateful) and NACLs (stateless).\nPerimeter Defense: Deploy WAF (Web Application Firewall) and Shield to protect applications against DDoS and Layer 7 attacks.\n5. Pillar 4: Data Protection Encryption: Ensure data is encrypted both at-rest (stored in S3, EBS, RDS) and in-transit (transmitted via TLS/SSL).\nKey and Secrets Management: Use KMS (Key Management Service) to manage primary encryption keys, control key policies, and key rotation. Use Secrets Manager to store and automatically rotate secrets (database passwords, API keys).\n6. Pillar 5: Incident Response IR Lifecycle: Guidance on adhering to the AWS standard lifecycle (Prepare, Detect, Respond, Recover).\nResponse Automation: Develop automated Playbooks using Lambda or Step Functions for common incidents like compromised IAM keys or EC2 malware detection. Key steps include Snapshot, isolation, and evidence collection.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/4.6-event6/",
	"title": "Event 6",
	"tags": [],
	"description": "",
	"content": "EVENT REPORT: AWS FOR SAP USING GENERATIVE AI Time: 1:00 PM - 5:00 PM.\nSpeaker: Nonthakorn Junthapol.\nTopic: AWS for SAP Using Generative AI \u0026amp; SAP ABAP capabilities and Amazon Q Developer.\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City.\nEvent Objective: To explore how Generative Artificial Intelligence (GenAI) can optimize and modernize the SAP environment, focusing on enhancing ABAP development productivity through Amazon Q Developer.\nCONTEXT AND GOALS OF GENAI IN SAP 1. Modernizing SAP on AWS The event established the foundation by affirming AWS\u0026rsquo;s role as the preferred cloud platform for SAP S/4HANA systems (including the RISE with SAP model).\nDiscussion covered traditional challenges in the SAP environment: the complexity of Legacy ABAP code, the need for modernization (e.g., migrating to S/4HANA), and slow development speed.\n2. The Role of Generative AI GenAI was introduced as a strategic tool to overcome these challenges, especially in code automation, refactoring, and data interaction.\nServices like Amazon Bedrock (or custom models on SageMaker) can be used to analyze unstructured SAP data (e.g., PO documents, Invoices) after extraction via AWS.\nDEEP DIVE: AMAZON Q DEVELOPER AND ABAP CAPABILITIES 3. Introducing Amazon Q Developer Amazon Q Developer is an AI assistant designed to accelerate software development, customized to understand the context of AWS infrastructure and APIs.\nA key highlight is its ability to interact using natural language to solve technical issues and generate code.\n4. Boosting Productivity with SAP ABAP The core focus of the event delved into how Amazon Q directly supports ABAP developers:\nAmazon Q Capability Application in ABAP Value Proposition Code Generation Quickly creating ABAP code snippets for BAPIs, Function Modules, or standard ALV reports. Increases initial coding speed. Code Explanation Analyzing and explaining complex or sparsely used legacy ABAP code segments. Reduces maintenance time and code learning curve. Refactoring \u0026amp; Modernization Supporting the conversion of old ABAP code to more modern object-oriented (OOP) syntax and principles (e.g., preparing for S/4HANA). Lowers the risk and cost of system migration/upgrade. Troubleshooting Suggesting solutions and debugging guidance based on error messages in the SAP environment. Minimizes Mean Time To Recovery (MTTR). 5. Integration Mechanism and Security Amazon Q functions as an abstraction layer, accessing ABAP source code through authorized connections (potentially via AWS Connector tools or integration with the development environment).\nData Security: It was emphasized that ABAP source code data is processed securely and is not used to train the underlying Amazon Q model, ensuring the privacy and security of enterprise intellectual property.\nEvent Photos. "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/4-eventparticipants/",
	"title": "Event Participants",
	"tags": [],
	"description": "",
	"content": "During my internship, I participated in six events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Cloud Day Vietnam 2025 \u0026amp; GenAI Track.\nTime: 09:00 AM - 17:00 PM, Thursday December 18, 2025.\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City.\nRole: Attendee.\nEvent 2 Event Name: AWS Cloud Mastery Series #1 : AI/ML/GenAI on AWS\nTime: 8:30 AM – 11:30 AM, Saturday, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock\nTime: 9:00 AM - 12:00 PM ; Friday, December 5, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #2 : DevOps on AWS\nTime: 8:30 AM – 17:00 PM ; Monday, November 17, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #3 : Security on AWS\nTime: 8:30 AM – 12:00 AM ; Saturday, November 29, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 6 Event Name: AWS for SAP Using Generative AI : SAP ABAP capabilities and Amazon Q Developer\nTime: 13:00 PM – 17:00 PM ; Thursday, November 20, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.5-nat/",
	"title": "Create NAT Gateway",
	"tags": [],
	"description": "",
	"content": "The NAT Gateway allows instances in the Private Subnet to access the Internet without being publicly exposed. This is how the private EC2 will yum install, download updates, etc.\n5.1 Allocate Elastic IP In the left VPC menu, select Elastic IPs Click Allocate Elastic IP address Choose default settings Click Allocate 5.2 Create NAT Gateway In the left VPC panel, go to NAT gateways Click Create NAT gateway Configure: Field Value Name Workshop-NAT Availability mode Zonal Subnet Public-Subnet Connectivity type Public Elastic IP allocation Select the one you just created Click Create NAT gateway 5.3 Wait for NAT Gateway to become \u0026ldquo;Available\u0026rdquo; Status starts as Pending Wait until it changes to Available Result Check Resource Status NAT Gateway (Workshop-NAT) Available Elastic IP Associated You’re now ready to route private subnet traffic through NAT.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "This is our group Workshop. Please review the below contents. Content Overview Prerequisites Create VPC \u0026amp; Subnets Create Internet Gateway Create NAT Gateway Configure Route Tables Launch EC2 Instances Connectivity Tests Cleanup "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.6-routetb/",
	"title": "Configure Route Tables",
	"tags": [],
	"description": "",
	"content": "Route Tables decide how traffic flows inside your VPC.\nIn this component, you will:\nCreate separate route tables for public and private subnets Route Internet traffic from the public subnet → Internet Gateway Route private subnet traffic → NAT Gateway for outbound access 6.1 Create Route Table for Public Subnet In VPC console, open Route Tables Click Create route table Enter: Name: Public-RT VPC: Workshop-VPC Click Create route table 6.2 Add Route to Internet Gateway Select route table Public-RT Go to the Routes tab Click Edit routes → Add route Enter: Destination: 0.0.0.0/0 Target: Internet Gateway (Workshop-IGW) Click Save changes 6.3 Associate Public Subnet with Public Route Table Still inside Public-RT page Click Subnet associations Under Explicit subnet associations tab → Edit subnet associations Select Public-Subnet Save 6.4 Create Route Table for Private Subnet Click Create route table Enter: Name: Private-RT VPC: Workshop-VPC Click Create route table This process is similar to 6.1 with only minor differences. Please see 6.1 section for reference.\n6.5 Add Route to NAT Gateway (Private Subnet Outbound Access) Select Private-RT Go to Routes → Edit routes Add: Destination: 0.0.0.0/0 Target: NAT Gateway (Workshop-NAT) Save 6.6 Associate Private Subnet Go to Subnet associations (of Private-RT route table) Under Explicit subnet associations tab → Edit subnet associations Select Private-Subnet Save Result Check You should now see:\nRoute Table Subnet Internet Path Public-RT Public-Subnet Internet Gateway Private-RT Private-Subnet NAT Gateway At this point, networking backbone is fully functional.\nNext up — we deploy EC2 instances to test the security measures.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/6-self-evaluation/",
	"title": "Self-Evaluation",
	"tags": [],
	"description": "",
	"content": "During my internship at [Amazon Web Service] from [September] to [December], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in AWS Cloud Heath Dashboard, through which I improved my skills in programming, reporting, communication.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality. ☐ ☐ ✅ 2 Ability to learn Ability to absorb new knowledge and learn quickly. ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions. ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality. ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes. ☐ ✅ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself. ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly. ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams. ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment. ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity. ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team. ☐ ✅ ☐ 12 Overall General evaluation of the entire internship period. ☐ ✅ ☐ Needs Improvement. Strengthen discipline and strictly comply with the rules and regulations of the company or any organization.\nImprove problem-solving thinking.\nEnhance communication skills in both daily interactions and professional contexts, including handling situations effectively.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/7-feedback/",
	"title": "Feedback",
	"tags": [],
	"description": "",
	"content": " Here, you can freely share your personal opinions and experiences during the First Cloud Journey program to help the FCJ team improve any shortcomings based on the following categories:\nOverall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What are you most satisfied with during your internship?\n→ The mentors and team admins were always supportive and willing to help, which made tasks much easier to understand and complete.\nWhat do you think the company should improve for future interns?\n→ The onboarding process could be improved to help interns get familiar with the environment and their tasks more quickly.\nIf you were to recommend this internship to your friends, would you do so? Why?\n→ Yes. The working environment is friendly, supportive, and provides good learning opportunities for both technical and soft skills.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? → No, I don\u0026rsquo;t have any thing to say. It\u0026rsquo;s perfect.\nWould you like to continue this program in the future? → Yes. I would be happy to join future programs if given the opportunity.\nOther comments (feel free to share): → Everything was well-organized, and the team was very helpful. Thank you for the experience.\n"
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.7-ec2/",
	"title": "Launch EC2 Instances",
	"tags": [],
	"description": "",
	"content": "You will now deploy two EC2 instances:\nInstance Subnet Access EC2-Public Public-Subnet SSH directly from Internet EC2-Private Private-Subnet No public IP — accessible only through Public EC2 Both will use the same AMI and instance type for simplicity.\n7.1 Create a Key Pair Go to EC2 Console Left panel → Key Pairs Click Create key pair Set: Name: Workshop-Key Type: RSA Format: .pem (Linux/Mac) or .ppk (Windows PuTTY) Download and store securely This key will be used later for SSH.\n7.2 Launch Public EC2 Instance In EC2 Console → Click Instances → Click Launch instances Name: EC2-Public Select AMI: Amazon Linux Instance type: t3.micro (Free tier eligible) Select existing key pair: Workshop-Key Network settings (Click Edit to show menu): VPC: Workshop-VPC Subnet: Public-Subnet Auto-assign Public IP: Enabled Configure security group: New SG name: Public-EC2-SG Inbound rule: Type: SSH Source Type: Custom Source: 0.0.0.0/0 Leave everything else as default. Launch instance 7.3 Launch Private EC2 Instance In EC2 Console → Click Instances → Click Launch instances again Name: EC2-Private AMI + instance type = same as public EC2 Use key pair: Workshop-Key Network settings: VPC: Workshop-VPC Subnet: Private-Subnet Auto-assign Public IP: Disabled Security Group: Name: Private-EC2-SG Type: SSH Source Type: Custom Source: Public-EC2-SG (not the Internet) 📸 Screenshot here: Private EC2 config with No Public IP 7.4 Verify Instances Instance IP Expected EC2-Public Has IPv4 Public Can SSH from your machine EC2-Private No Public IP Only reachable via Public EC2 "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.8-connectivity-tests/",
	"title": "Connectivity Tests",
	"tags": [],
	"description": "",
	"content": "Now that both EC2 instances are running, it\u0026rsquo;s time to validate network behavior and confirm the VPC is functioning correctly.\nThis component verifies three things:\nPublic EC2 is reachable from your local machine Private EC2 is only reachable from the Public EC2 (not directly from the internet) Private EC2 can access the internet through the NAT Gateway 8.1 Connect to the Public EC2 Instance Open the EC2 Console → Instances Copy the Public IPv4 of EC2-Public SSH into the instance This step is dependent on what type of machine you\u0026rsquo;re using and can vary among different tools. We are using Powershell on a Windows 11 OS PC for this Workshop. You can use other alternatives if you prefer.\nssh -i \u0026#34;Workshop-Key.pem\u0026#34; ec2-user@\u0026lt;PUBLIC_IP_HERE\u0026gt; Example: ssh -i \u0026ldquo;Workshop-Key.pem\u0026rdquo; ec2-user@54.218.10.102\nRun the command and you will see something like this: Terminal connected to EC2-Public. For security reasons, we had to blurred some details.\n8.2 SSH from Public EC2 to Private EC2 Before you can do this step, you must copy your EC2 instance key/pair into the public EC2 instance EC2-Public This is not a recommended action by AWS. As it is a great security risk to put access keys onto EC2 instances. However, for the sake of simplicity in our purpose of testing connections. You can do this.\nFrom the terminal on your machine (logged out of any EC2 intances). Run this: scp -i \u0026#34;Workshop-Key.pem\u0026#34; Workshop-Key.pem ec2-user\u0026lt;PUBLIC_IP_HERE\u0026gt;:/home/ec2-user/ This copies your access key into the public EC2 instance EC2-Public to be used later in accessing the private EC2 instance EC2-Private\nThen SSH into EC2-Public like you did before in section 8.1 and run: chmod 400 Workshop-Key.pem This limit the permissions of the copied access key, securing it. Allowing you to use it later to SSH into the private EC2 instance EC2-Private\nThen run this: ssh -i \u0026#34;Workshop-Key.pem\u0026#34; ec2-user@\u0026lt;PRIVATE_IP_HERE\u0026gt; Success, you have successfully SSH into the private EC2 instance EC2-Private from the only allowed source of connection: The public EC2 instance EC2-Public\n8.3 Test Internet Connectivity from Private Instance Run this: ping -c 3 google.com sudo yum update -y Expected behavior: Action Result ping google.com Replies received yum update Packages download successfully → If this works, NAT Gateway routing is confirmed.\nSuccessful internet connection from the private EC2 instance EC2-Private\n8.4 Validate Security Behavior (Important Check) Test Expected Result Your PC → Private instance SSH Blocked Public EC2 → Private EC2 SSH Allowed Private EC2 → Internet Works via NAT → This confirms public exposure = controlled, and private access = secure + functional.\nAs expected. Connection from local machine into the private EC2 instance EC2-Private is not allowed. Security measures working as intended.\nThis concludes the Connectivity Tests "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/5-workshop/5.9-cleanup/",
	"title": "Clean Up",
	"tags": [],
	"description": "",
	"content": "To avoid unnecessary charges — especially from the NAT Gateway — you should remove all created resources after finishing the workshop.\nFollow the steps below in order:\n9.1 Terminate EC2 Instances Open EC2 Console Select both EC2-Public and EC2-Private Click Instance state → Terminate (This process may take some time) Confirm termination 9.2 Delete NAT Gateway Go to VPC Console → NAT Gateways Select Workshop-NAT Click Actions → Delete NAT Gateway (This process may take some time) Confirm the action Wait until NAT Gateway shows as Deleted before moving on.\n9.3 Release Elastic IP After NAT Gateway is deleted:\nGo to Elastic IPs Select the allocated address Click Actions → Release Elastic IP address Confirm release (empty Elastic IP addresses list) 9.4 Detach and Delete Internet Gateway In Internet Gateways Select Workshop-IGW Click Actions → Detach from VPC Then Actions → Delete Internet gateway Confirm deletion (empty Internet gateways list) 9.5 Delete Subnets Go to Subnets Delete Public-Subnet Delete Private-Subnet Confirm deletion (empty Subnets list) 9.6 Delete VPC In VPC Console Select Workshop-VPC Click Actions → Delete VPC Confirm deletion (empty VPCs list) 9.7 Delete Route Tables Open Route Tables Select Public-RT → Delete Select Private-RT → Delete Confirm deletion (created route tables no longer exist) Cleanup Complete "
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/FCJ-Workshop-Official/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]